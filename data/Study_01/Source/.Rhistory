df_reg$Intense[df_reg$Intense == "A little"] <- 1
df_reg$Intense[df_reg$Intense == "A moderate amount"] <- 2
df_reg$Intense[df_reg$Intense == "A lot"] <- 3
df_reg$Intense[df_reg$Intense == "A great deal"] <- 4
df_reg$Intense <- as.numeric(df_reg$Intense)
as.data.frame(df_reg[which(is.na(df_reg$Intense)),])
# Factoring the direction variable
## Scoring Direction ----
df_reg$Reg[df_reg$Reg == "I attempted to reduce it"] <- "Decrease"
df_reg$Reg[df_reg$Reg == "I attempted to intensify it"] <- "Increase"
df_reg$Reg[df_reg$Reg == "I did not attempt to change it"] <- "Neither"
df_reg$Reg <- as.factor(df_reg$Reg)
as.data.frame(df_reg[which(is.na(df_reg$Reg)),])
# Quantifying the success variable
## Scoring Success ----
df_reg$RegSuccess[df_reg$RegSuccess == "Not at all successful"] <- 0
df_reg$RegSuccess[df_reg$RegSuccess == "A little  successful"] <- 1
df_reg$RegSuccess[df_reg$RegSuccess == "Moderately successful"] <- 2
df_reg$RegSuccess[df_reg$RegSuccess == "Successful"] <- 3
df_reg$RegSuccess[df_reg$RegSuccess == "Very  successful"] <- 4
df_reg$RegSuccess <- as.numeric(df_reg$RegSuccess)
# ----- RENAMING STUFF -----
## Renaming Columns ----
df_reg <- rename(df_reg, c(EventNum = Event,
EventKey = Keyword,
EventDesc = Desc,
EmoNum = Number))
# ----- TRANSFORMING VARIABLES -----
## Person Centering and Aggregating ----
df_reg <- dplyr::group_by(df_reg, as.factor(PID))
df_reg <- dplyr::mutate(df_reg,
Intense.pmean = mean(Intense, na.rm=T),
RegSuccess.pmean = mean(RegSuccess, na.rm=T),
Intense.pc = Intense - mean(Intense, na.rm=T),
RegSuccess.pc = RegSuccess - mean(RegSuccess, na.rm=T))
df_reg <- ungroup(df_reg)
## Z Scoring Aggregates ----
df_reg <- group_by(df_reg, PID)
df_reg$Intense.pmean.z <- as.numeric(scale(df_reg$Intense.pmean, scale = T, center = T))
df_reg$RegSuccess.pmean.z <- as.numeric(scale(df_reg$RegSuccess.pmean, scale = T, center = T))
df_reg <- ungroup(df_reg)
## Z Scoring Variables ----
df_reg$Intense.z <- as.numeric(scale(df_reg$Intense, scale=T, center=T))
df_reg$RegSuccess.z <- as.numeric(scale(df_reg$RegSuccess, scale=T, center=T))
df_reg$Intense.pc.z <- as.numeric(scale(df_reg$Intense.pc, scale=T, center=T))
df_reg$RegSuccess.pc.z <- as.numeric(scale(df_reg$RegSuccess.pc, scale=T, center=T))
# ----- MERGING CLEANED EMOTION DATAFRAMES -----
### ----- CLEANED EMOTIONS -----
## Reading Cleaned, Lemmatized Emotion .CSV ----
df_emo <- read.csv(paste0(Import,"df_emo_lemmatization.csv"),
header = T,
na.strings = "NA") %>%
remove_NAs(cols = TRUE,
rows = TRUE) %>%
.[,-1]
## Converting all emotions to lowercase ----
df_reg$Emotion <- tolower(df_reg$Emotion)
df_emo$Emotion <- tolower(df_emo$Emotion)
df_reg$Emotion <- trimws(df_reg$Emotion)
## Merging Emotion Dataframes ----
df_reg <- merge(df_reg,
df_emo,
by = "Emotion",
all.x = T)
## Removing duplicate rows ----
df_reg <- df_reg %>%
distinct()
## Cleaning Emo Space ----
rm(df_emo)
### ----- NRC LEXICON -----
## Sourcing Experience Data ----
source(paste0(Scripts, "NRC.R"))
## Z-Scoring NRC ----
nrc$Valence_z <- as.numeric(scale(as.numeric(nrc$Valence)))
nrc$Arousal_z <- as.numeric(scale(as.numeric(nrc$Arousal)))
nrc$Dominance_z <- as.numeric(scale(as.numeric(nrc$Dominance)))
## Merging Emotion Dataframes ----
df_reg <- merge(df_reg,
nrc,
by.x = "EmoMod",
by.y = "Word",
all.x = T)
## Cleaning NRC Space ----
rm(nrc)
# ----- CHECKING MERGES -----
# Ideally, every word people cited would be matched to an
# NRC entry. There may be cases where R could not find matches
# due to slight word differences, blank space, misspellings,
# etc. I'm going to manually review those cases where there was
# no NRC match just to check that it's not an issue.
## Isolating Relevant Rows ----
df_reg$EmoMod[!is.na(df_reg$EmoMod) & is.na(df_reg$Valence)] %>%
unique() %>%
sort()
# Not horrible.
## Correcting Structures ----
df_reg$PID <- as.factor(df_reg$PID)
df_reg$EventNum <- as.factor(df_reg$EventNum)
df_reg$EmoNum <- as.factor(df_reg$EmoNum)
df_reg$Timing <- as.factor(df_reg$Timing)
df_reg$RegSuccess <- as.numeric(df_reg$RegSuccess)
df_reg$Intense <- as.numeric(df_reg$Intense)
df_reg$Valence <- as.numeric(df_reg$Valence)
df_reg$Arousal <- as.numeric(df_reg$Arousal)
df_reg$Dominance <- as.numeric(df_reg$Dominance)
df_reg$EmoMod <- tolower(df_reg$EmoMod)
df_reg$EmoMod <- tolower(df_reg$EmoMod)
## Z-Scoring Qualtrics Events ----
df_reg$Intense_z <- as.numeric(scale(df_reg$Intense))
df_reg$RegSuccess_z <- as.numeric(scale(df_reg$RegSuccess))
## Creating a Cateogry Superfactor ----
df_reg$EmoCat <- NA
for (i in 1:nrow(df_reg)){
cats <- NA
if (df_reg$anger[i] == 1 & !is.na(df_reg$anger[i])){
cats <- c(cats, "Anger")
}
if (df_reg$anticipation[i] == 1 & !is.na(df_reg$anticipation[i])){
cats <- c(cats, "Anticipation")
}
if (df_reg$disgust[i] == 1 & !is.na(df_reg$disgust[i])){
cats <- c(cats, "Disgust")
}
if (df_reg$fear[i] == 1 & !is.na(df_reg$fear[i])){
cats <- c(cats, "Fear")
}
if (df_reg$joy[i] == 1 & !is.na(df_reg$joy[i])){
cats <- c(cats, "Joy")
}
if (df_reg$sadness[i] == 1 & !is.na(df_reg$sadness[i])){
cats <- c(cats, "Sadness")
}
if (df_reg$surprise[i] == 1 & !is.na(df_reg$surprise[i])){
cats <- c(cats, "Surprise")
}
if (df_reg$trust[i] == 1 & !is.na(df_reg$trust[i])){
cats <- c(cats, "Trust")
}
if (length(cats) > 1){
cats <- cats[-1]
df_reg$EmoCat[i] <- paste(cats, collapse =", ")
}
}
# Participants were shown their previously noted events at a later date and asked to recall their emotional experiences
# However. because they did not enter it themselves, Qualtrics didn't export it. Therefore, I need to copy the recall info
# From when it was initially written which is what I'm doing here.
for (i in unique(sort(df_reg$PID))){
for (j in unique(sort(df_reg$EventNum))){
df_reg$EventKey[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "MemReg"] <- df_reg$EventKey[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "ImmReg"][1]
df_reg$EventDesc[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "MemReg"] <- df_reg$EventDesc[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "ImmReg"][1]
}
}
# Now I'm creating a new dataframe to perfrom the regulation IRR, so I'm excluding any events that
# did not indicate regulation, did not describe regulation, or did not describe an emotion.
# df <- subset(df_reg, df_reg$Reg != "Neither" & !is.na(df_reg$RegDesc) & !is.na(df_reg$EmoMod))
# Exporting that dataframe
# write.csv(df, "S:/Murty_Group/studies/frightnight.02/admin/regulation/irr/strategies_Corrected.csv")
# ---- MERGING CODING RESPONSES -----
## Reading Cleaned Coded .CSV ----
df_coding <- rbind(read.csv(paste0(Import,"coding_round1.csv"),
header = T,
na.strings = "NA"),
read.csv(paste0(Import,"coding_round2.csv"),
header = T,
na.strings = "NA"),
read.csv(paste0(Import,"coding_round3.csv"),
header = T,
na.strings = "NA"))
## Merging Coded Dataframes ----
df_reg <- merge(df_reg,
df_coding,
by.x = c("EmoMod", "Reg", "RegDesc", "EventKey", "EventDesc", "Intense"),
by.y = c("Emotion", "Reg", "RegDesc", "EventKey", "EventDesc", "Intense"),
all = T)
## Reading Practice Coded .CSV ----
df_coding <- read.csv(paste0(Import,"coding_round4.csv"),
header = T,
na.strings = "NA")
## Correcting Terminology
df_coding$Reg[df_coding$Reg == "Reduce"] <- "Decrease"
## Merging Coded Dataframes ----
for (i in 1:nrow(df_coding)){
target <- which(df_reg$Intense == df_coding$Intense[i] &
df_reg$Reg == df_coding$Reg[i] &
df_reg$RegDesc == df_coding$RegDesc[i] &
df_reg$EventDesc == df_coding$EventDesc[i] &
df_reg$EventDesc == df_coding$EventDesc[i] &
df_reg$EmoMod == df_coding$Emotion[i])
if (length(target) == 0){
paste("Row", i, "had no matches in the primary dataframe")
}
if (length(target) > 1){
paste("Row", i, "had multiple matches in the primary dataframe")
}
if (length(target) == 1){
df_reg$Attention.Deployment[target] <- df_coding$Attention.Deployment[i]
df_reg$Response.Modulation[target] <- df_coding$Response.Modulation[i]
df_reg$Reappraisal[target] <- df_coding$Reappraisal[i]
df_reg$Correct[target] <- df_coding$Correct[i]
}
}
## Cleaning our space
rm(df_coding, i, j, cats, target)
## Removing duplicate rows ----
df_reg <- df_reg %>%
distinct() %>%
remove_NAs()
# Preparing for Export ----
## Checking structure
# str(df_reg)
## Restructuing factors
df_reg$EmoMod <- as.factor(df_reg$EmoMod)
df_reg$Stage <- as.factor(df_reg$Stage)
df_reg$Sect <- as.factor(df_reg$Sect)
# df_reg$anger <- as.factor(df_reg$anger)
# df_reg$anticipation <- as.factor(df_reg$anticipation)
# df_reg$disgust <- as.factor(df_reg$disgust)
# df_reg$fear <- as.factor(df_reg$fear)
# df_reg$joy <- as.factor(df_reg$joy)
# df_reg$sadness <- as.factor(df_reg$sadness)
# df_reg$surprise <- as.factor(df_reg$surprise)
# df_reg$trust <- as.factor(df_reg$trust)
# df_reg$Attention.Deployment <- as.factor(df_reg$Attention.Deployment)
# df_reg$Response.Modulation <- as.factor(df_reg$Response.Modulation)
# df_reg$Reappraisal <- as.factor(df_reg$Reappraisal)
# df_reg$Correct <- as.factor(df_reg$Correct)
## Releveling Reg
df_reg$Reg <- as.factor(as.character(df_reg$Reg)) %>%
relevel(., ref = "Neither")
## Checking Reg's levels
levels(df_reg$Reg)
### ----- SUPPLEMENTALS -----
## Sourcing Experience Data ----
source(paste0(Scripts, "Suppl_dfs.R"))
install.packages("lexicon")
pacman::p_load(effects,
lme4,
performance,
stargazer,
tidyverse)
source("https://github.com/Wjpmitchell3/stinkR/blob/main/remove_NAs.R?raw=TRUE", local = T)
source("https://github.com/Wjpmitchell3/stinkR/blob/main/make_df.R?raw=TRUE", local = T)
options(scipen=100)
options(digits=3)
options(tinytex.verbose = TRUE)
# Identifying our main directory
WorkDir <- "C:/Users/wjpmi/Dropbox/My PC (UncleSplashysSaddnessEmporium)/Desktop/Grad School/Projects/Complete/Fright Night/Public_Records/"
# Identifying specific directories to read and write from
Export <- paste0(WorkDir, "data/Study_02/Derivative/")
Import <- paste0(WorkDir, "data/Study_02/Raw/")
Plots <- paste0(WorkDir, "plots/")
source(paste0(WorkDir,"scripts/3_Study2_DFcreation/Regulation_df.R"))
## Packages I Use ----
library(psych)
library(tidyverse)
source("https://github.com/Wjpmitchell3/stinkR/blob/main/remove_NAs.R?raw=TRUE", local = T)
## Number Formatting ----
options(scipen=100)
options(digits=3)
options(tinytex.verbose = TRUE)
## Specifying Filepaths ----
WorkDir <- "C:/Users/wjpmi/Dropbox/My PC (UncleSplashysSaddnessEmporium)/Desktop/Grad School/Projects/Complete/Fright Night/Public_Records/"
Scripts <- paste0(WorkDir,"scripts/3_Study2_DFcreation/")
Export <- paste0(WorkDir, "data/Study_02/Raw/")
Import <- paste0(WorkDir, "data/Study_02/Source/")
## Pulling in Cleaned Data ----
source(paste0(Scripts,"Data_Cleaning.R"))
## Checking Number of Entries ----
which(table(df$PID) != 3)
## Removing Pre-Exposure ----
df <- subset(df, df$Stage != "Pre-Exposure")
(issues <- sort(unique(df$PID))[which(table(df$PID) != 2)])
## Removing issue rows ----
for (i in issues){
if (any(df$Finished != TRUE & df$PID == i)){
df <- df[-(which(df$Finished != TRUE & df$PID == i)),]
}
}
## Checking issue rows ----
which(table(df$PID) != 2)
## Cleaning Cleaning Dataframes Section ----
rm(i, issues)
## Isolating Relevant variables ----
df_reg <- df[,c(18:19, 878:956, 713:804, 957:1122)]
## Removing Timing Columns ----
df_reg <- df_reg[,-c(grep("First.Click", colnames(df_reg)),
grep("Last.Click", colnames(df_reg)),
grep("Page.Submit", colnames(df_reg)),
grep("Click.Count", colnames(df_reg)))]
# Here I'm creating an array of the emotion-related questions we ask for each section
# or event
## Specifying Emotion Questions ----
EmotionQs <- c(paste0("Emotion", 1:5),
paste0("Emotion", 1:5,"Intense"),
paste0("Emotion", 1:5,"Reg"),
paste0("Emotion", 1:5,"RegDesc"),
paste0("Emotion", 1:5,"RegSuccess"))
## Specifying Event Questions ----
ImmEventQs <- c("CryptDesc", "MachShopDesc", "Keyword")
DelEventQs <- c("Desc", "Keyword")
## Creating Regulation Memory Column Names ----
# Creating the variable
EmotionQs.MemReg <- NA
# Populating variable with Emotion Qs
for (i in paste0("0", 1:3,"-")){
EmotionQs.MemReg <- c(EmotionQs.MemReg, paste0("MemReg_", i, EmotionQs))
}
# Removing the initial variable value
EmotionQs.MemReg <- EmotionQs.MemReg[-1]
## Specifying Column Names for Emotions Immediately After ----
# Creating the variable
EmotionQs.ImmReg <- NA
# Populating the variable with EventQs
for (i in paste0("0", 1:3,"-")){
EmotionQs.ImmReg <- c(EmotionQs.ImmReg, paste0("ImmReg_", i, ImmEventQs))
}
# Removing the initial variable value
EmotionQs.ImmReg <- EmotionQs.ImmReg[-1]
# Populating variable with Emotion Qs
for (i in paste0("0", 1:3,"-")){
EmotionQs.ImmReg <- c(EmotionQs.ImmReg, paste0("ImmReg_", i, EmotionQs))
}
## Specifying Column Names for Emotions One Week Later ----
# Creating the variable
EmotionQs.DelReg <- NA
# Populating the variable with EventQs
for (i in paste0("0", 1:6,"-")){
EmotionQs.DelReg <- c(EmotionQs.DelReg, paste0("DelReg_", i, DelEventQs))
}
# Removing the initial variable value
EmotionQs.DelReg <- EmotionQs.DelReg[-1]
# Populating variable with Emotion Qs
for (i in paste0("0", 1:6,"-")){
EmotionQs.DelReg <- c(EmotionQs.DelReg, paste0("DelReg_", i, EmotionQs))
}
## Renaming Columns ----
Cols.Reg <- c("PID", "Stage", EmotionQs.MemReg, EmotionQs.ImmReg, EmotionQs.DelReg)
colnames(df_reg) <- Cols.Reg
colnames(df_reg)[1:20]
## Cleaning Renaming Columns ----
rm(Cols.Reg, EmotionQs.MemReg, EmotionQs.ImmReg, EmotionQs.DelReg, ImmEventQs, DelEventQs, EmotionQs, i)
## Pivoting Dataframe Based on Timing ----
df_reg <- pivot_longer(data = df_reg,
cols = grep("\\_", colnames(df_reg)),
names_to = c("Timing", ".value"),
names_sep = "\\_",
values_drop_na = TRUE)
## Pivoting Dataframe Based on Event ----
df_reg <- pivot_longer(data = df_reg,
cols = grep("\\-", colnames(df_reg)),
names_to = c("Event", ".value"),
names_sep = "\\-",
values_drop_na = TRUE)
## Pivoting Dataframe Based on Event ----
colnames(df_reg) <- c("PID", "Stage", "Timing", "Event", "Emotion1_", "Emotion2_", "Emotion3_", "Emotion4_", "Emotion5_",
"Emotion1_Intense", "Emotion2_Intense", "Emotion3_Intense", "Emotion4_Intense",
"Emotion5_Intense", "Emotion1_Reg", "Emotion2_Reg", "Emotion3_Reg",
"Emotion4_Reg", "Emotion5_Reg", "Emotion1_RegDesc", "Emotion2_RegDesc",
"Emotion3_RegDesc", "Emotion4_RegDesc", "Emotion5_RegDesc",
"Emotion1_RegSuccess", "Emotion2_RegSuccess", "Emotion3_RegSuccess",
"Emotion4_RegSuccess", "Emotion5_RegSuccess", "CryptDesc", "MachShopDesc", "Keyword", "Desc")
Cols.Emo <- grep("(Emotion._)$", colnames(df_reg))
names(df_reg)[Cols.Emo] <- paste0(names(df_reg)[Cols.Emo], "Emotion")
df_reg <- pivot_longer(data = df_reg,
cols = starts_with("Emotion"),
names_to = c( "Number", ".value"),
names_sep = "_",
names_repair = "unique",
values_drop_na = TRUE)
df_reg$Number <- gsub("Emotion", "", df_reg$Number )
rm(Cols.Emo)
## Making NAs consistent ----
df_reg$Emotion[df_reg$Emotion == "n/a" |
df_reg$Emotion == "N/a"] <- NA
## Identifying rows with compound emotions ----
rows <- which(str_detect(string =  df_reg$Emotion,
pattern = "\\/"))
## Splitting rows with compound emotions ----
# Once duplicated, remove the first emotion from each of the originals
for (i in 1:length(rows)){
df_reg <- add_row(df_reg, df_reg[rows[i],])
df_reg$Emotion[rows[i]] <- str_replace_all(string = df_reg$Emotion[rows[i]],
pattern = ".*\\/",
replacement = "")
}
# Remove the second emotion from each of the duplicates
df_reg$Emotion <- str_replace_all(string = df_reg$Emotion,
pattern = "\\/.*",
replacement = "")
## Cleaning the space ----
rm(rows)
# Consolidating the descriptions people provided of the events they
# responded to. They are currently separated into columns based upon
# the section in which they occurred. No row should have data in more
# than one of these columns, since an event can only occur in one section.
# The QA check here is just making sure that if a column in any given row
# has data in it, that the other columns in that row do not have data, and
# it will output an error if that's the case.
## Consolidating Descriptions ----
df_reg$Sect <- NA
for (i in 1:length(rownames(df_reg))){
if (!is.na(df_reg$CryptDesc[i]) & !is.na(df_reg$MachShopDesc[i])){
print(paste0("Error: Row ", i))
}
if (!is.na(df_reg$Desc[i]) & !is.na(df_reg$MachShopDesc[i])){
print(paste0("Error: Row ", i))
}
if (!is.na(df_reg$CryptDesc[i]) & !is.na(df_reg$Desc[i])){
print(paste0("Error: Row ", i))
}
if (!is.na(df_reg$CryptDesc[i]) & is.na(df_reg$MachShopDesc[i]) & is.na(df_reg$Desc[i])){
df_reg$Desc[i] <- df_reg$CryptDesc[i]
df_reg$Sect[i] <- "Crypt"
}
if (is.na(df_reg$CryptDesc[i]) & !is.na(df_reg$MachShopDesc[i]) & is.na(df_reg$Desc[i])){
df_reg$Desc[i] <- df_reg$MachShopDesc[i]
df_reg$Sect[i] <- "MachShop"
}
}
df_reg <- df_reg[,-(grep("^CryptDesc|^MachShopDesc",colnames(df_reg)))]
## QA Checks ----
badrows <- NA
for (i in 1:length(rownames(df_reg))){
if (!is.na(df_reg$RegSuccess[i]) & is.na(df_reg$Emotion[i])){
print(paste0("Error: Row ", i, " has no emotion, but reports regulation"))
badrows <- c(badrows, i)
}
if (!is.na(df_reg$Reg[i])){
if (df_reg$Reg[i] == "I did not attempt to change it" & !is.na(df_reg$RegSuccess[i])){
print(paste0("Error: Row ", i, " reports not regulating, but then has regulation information"))
badrows <- c(badrows, i)
}
if (df_reg$Reg[i] != "I did not attempt to change it" & is.na(df_reg$RegSuccess[i])){
print(paste0("Error: Row ", i, " reports regulating, but then has no regulation information"))
badrows <- c(badrows, i)
}
}
}
badrows <- badrows[-1]
df_reg <- df_reg[-badrows[1:(length(badrows)-1)],]
rm(i, badrows)
# Changing the value of the intensity scores so that they they can be analyzed
## Scoring Intensity ----
df_reg$Intense[df_reg$Intense == "None at all"] <- 0
df_reg$Intense[df_reg$Intense == "A little"] <- 1
df_reg$Intense[df_reg$Intense == "A moderate amount"] <- 2
df_reg$Intense[df_reg$Intense == "A lot"] <- 3
df_reg$Intense[df_reg$Intense == "A great deal"] <- 4
df_reg$Intense <- as.numeric(df_reg$Intense)
as.data.frame(df_reg[which(is.na(df_reg$Intense)),])
# Factoring the direction variable
## Scoring Direction ----
df_reg$Reg[df_reg$Reg == "I attempted to reduce it"] <- "Decrease"
df_reg$Reg[df_reg$Reg == "I attempted to intensify it"] <- "Increase"
df_reg$Reg[df_reg$Reg == "I did not attempt to change it"] <- "Neither"
df_reg$Reg <- as.factor(df_reg$Reg)
as.data.frame(df_reg[which(is.na(df_reg$Reg)),])
# Quantifying the success variable
## Scoring Success ----
df_reg$RegSuccess[df_reg$RegSuccess == "Not at all successful"] <- 0
df_reg$RegSuccess[df_reg$RegSuccess == "A little  successful"] <- 1
df_reg$RegSuccess[df_reg$RegSuccess == "Moderately successful"] <- 2
df_reg$RegSuccess[df_reg$RegSuccess == "Successful"] <- 3
df_reg$RegSuccess[df_reg$RegSuccess == "Very  successful"] <- 4
df_reg$RegSuccess <- as.numeric(df_reg$RegSuccess)
## Renaming Columns ----
df_reg <- rename(df_reg, c(EventNum = Event,
EventKey = Keyword,
EventDesc = Desc,
EmoNum = Number))
# ----- TRANSFORMING VARIABLES -----
## Person Centering and Aggregating ----
df_reg <- dplyr::group_by(df_reg, as.factor(PID))
df_reg <- dplyr::mutate(df_reg,
Intense.pmean = mean(Intense, na.rm=T),
RegSuccess.pmean = mean(RegSuccess, na.rm=T),
Intense.pc = Intense - mean(Intense, na.rm=T),
RegSuccess.pc = RegSuccess - mean(RegSuccess, na.rm=T))
df_reg <- ungroup(df_reg)
## Z Scoring Aggregates ----
df_reg <- group_by(df_reg, PID)
df_reg$Intense.pmean.z <- as.numeric(scale(df_reg$Intense.pmean, scale = T, center = T))
df_reg$RegSuccess.pmean.z <- as.numeric(scale(df_reg$RegSuccess.pmean, scale = T, center = T))
df_reg <- ungroup(df_reg)
## Z Scoring Variables ----
df_reg$Intense.z <- as.numeric(scale(df_reg$Intense, scale=T, center=T))
df_reg$RegSuccess.z <- as.numeric(scale(df_reg$RegSuccess, scale=T, center=T))
df_reg$Intense.pc.z <- as.numeric(scale(df_reg$Intense.pc, scale=T, center=T))
df_reg$RegSuccess.pc.z <- as.numeric(scale(df_reg$RegSuccess.pc, scale=T, center=T))
## Reading Cleaned, Lemmatized Emotion .CSV ----
df_emo <- read.csv(paste0(Import,"df_emo_lemmatization.csv"),
header = T,
na.strings = "NA") %>%
remove_NAs(cols = TRUE,
rows = TRUE) %>%
.[,-1]
## Converting all emotions to lowercase ----
df_reg$Emotion <- tolower(df_reg$Emotion)
df_emo$Emotion <- tolower(df_emo$Emotion)
df_reg$Emotion <- trimws(df_reg$Emotion)
## Merging Emotion Dataframes ----
df_reg <- merge(df_reg,
df_emo,
by = "Emotion",
all.x = T)
## Removing duplicate rows ----
df_reg <- df_reg %>%
distinct()
## Cleaning Emo Space ----
rm(df_emo)
## Sourcing Experience Data ----
source(paste0(Scripts, "NRC.R"))
