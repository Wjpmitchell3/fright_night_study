---
title: "ER Choice v. Usage - Study 1 Dataframe Creation"
author: "W.J. Mitchell"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# SCRIPT START

```{r Packages I Use}
# If the pacman package manager is not currently installed on this system, install it.
  if (require("pacman") == FALSE){
    install.packages("pacman")
  }

  # Loading in my packages with my pacman manager
  pacman::p_load(here,
                 lexicon,
                 psych,
                 tidyverse)
  
  # Loading a custom function that will clean NA values from dataframes
  source("https://github.com/wj-mitchell/stinkR/blob/main/remove_NAs.R?raw=TRUE", local = T)
```

```{r Number Formatting}
options(scipen=100)
options(digits=3)
options(tinytex.verbose = TRUE)
```

The `here()` function should ideally identify our upper-level project directory. So, `WorkDir` below should be a filepath that looks something like `C:/Users/.../Documents/GitHub/fright_night_study/", or where ever you store these files. Then we'll have additional variables store filepaths within that directory for where we're reading the data from and where we're sending data to. 

```{r Setting Working Directories}
  # Identifying our main directory
  WorkDir <- here::here()


  # Identifying specific directories to read and write from
  Export <- paste0(WorkDir, "/data/Study_01/Raw/")
  Import <- paste0(WorkDir, "/data/Study_01/Source/")
  Plots <- paste0(WorkDir, "/plots/")
```

# LOADING IN DATA

```{r Loading Data}
df <- read.csv(file = paste0(Import, "qualtrics.csv"), 
               header = T, 
               sep=",", 
               stringsAsFactors = F,
               na.strings=c("","N/A"))
```

Routing made sense as a variable name when it was literally routing individuals to different question sets, but now that we are out of the context of collection, it might make more sense as "Stage", as it denotes what stage of data collection a participant's responses are from. 

```{r Renaming Routing} 
df <- rename(df, Stage = Routing)
```

Participant A-010 got away with entering A-10 once so we have to correct that

```{r Correcting A-010} 
df$PID[df$PID == "A-10"] <- "A-010"
```

A-012 entered several extra numbers following their ID for pre-exposure, so we have to correct that

```{r Correcting A-012} 
df$PID[df$PID == "A-01263772"] <- "A-012"
```

A-025 accidentally entered A-024 as the PID for the immediate post-exposure. Since there are now two A-024s for immediate post-exposure, we confirmed on the day of the incident that A-025 (who submitted as A-024) completed the immediate post-exposure questions at 8:20PM and the real A-024 completed the post-exposure questions at 8:27PM.

```{r Correcting A-025} 
df$PID[df$PID == "A-024" & df$EndDate == "10/12/21 18:20"] <- "A-025"
``` 

A-057 typed in A-052 for pre-exposure, but started their survey after A-052, so we can differentiate them based on that fact.

```{r Correcting A-057} 
df$PID[df$PID == "A-052" & df$StartDate == "10/13/21 20:12"] <- "A-057"
``` 

A-075 an extra space in their ID

```{r Correcting A-057} 
df$PID[df$PID == "A-075 "] <- "A-075"
``` 

Participant A-124 was originally assigned PID A-019, which was already in use. Therefore, we need to correct the instances in which the wrong PID was entered. This is simple to do if we just focus on the date on which data was entered. 

```{r Correcting Misattributions} 
df$PID[df$PID == "A-019" & df$Stage == "Pre-Exposure" & df$StartDate == "10/27/21 17:32"] <- "A-124"
df$PID[df$PID == "A-019" & df$Stage == "Immediate Post-Exposure" & df$StartDate == "10/27/21 18:47"] <- "A-124"
df$PID[df$Stage == "One Week Post-Exposure" & df$StartDate == "11/3/21 8:36"] <- "A-124"
df$PID[df$PID == "A-123" & df$Stage == "One Week Post-Exposure" & df$StartDate == "11/5/21 13:59"] <- "A-050"
``` 

A-120's tablet crashed just after having started the survey so it was restarted. As such, the second entry is the correct one. Unfortunately, it still did not register as complete because my initial plan (before we decided to run the sessions at ESP) was to dismiss any individuals who reported having been to TBTW in the past such that Qualtrics would just shut down if an individual indicated such and would inform the RA. Unfortunately, that became sort of dismissal became unfeasible when we were having people transport themselves there and I forgot to update Qualtrics to stop it. It really only means that we lost motivation data, which isn't such a bummer, but it also means the data is viewed as incomplete, so we need to change that.

```{r Correcting A-057} 
df$Progress[df$PID == "A-120" & df$StartDate == "10/26/21 15:50"] <- "100"
```

Participant filled out the questionnaire twice and we are using the first entry

```{r Correcting A-114}
df <- df[-(which(df$StartDate == "11/5/21 12:25" & df$PID == "A-114")),]
``` 

A few times we entered nonsense PIDs to test out Qualtrics. We'll remove those now.

```{r Removing Test Trials}
df <- df[-c(which(df$PID == "A-186"), which(df$PID == "1")),]
``` 

Participant A-004 has two submissions for the immediate post-exposure, the one submitted in error can be determined because the RA entered VOID for all free response options, so we're going to remove that one.

```{r Removing Non-Completers and Pilot Data} 
df <- subset(df, (df$Q907 != "VOID" | is.na(df$Q907)))
df <- df[-c(1,2),]
```

Participants A-018, A-114, and A-120 all have multiple entries, which are only partially completed so we will remove those as well. I'm going to run a general function to search For any cases where a participant has two records and one of them is complete.

```{r Removing Duplicate Entries With One Partial}
for (i in sort(unique(df$PID))){
  for (j in sort(unique(df$Stage))){
    if (any(df$PID == i & df$Stage == j & df$Progress == 100)){
      if (any(df$PID == i & df$Stage == j & df$Progress != 100)){
        df <- df[-which(df$PID == i & df$Stage == j & df$Progress != 100),]
      }
    }
  }
}
```

# CLEANING DATAFRAMES

It may be the case that some participants do not have data at each of the possible points: Pre-Exposure, Post-Exposure, and Delay. Here, I'm checking how many entries each participant has provided and telling R to identify which participants don't have three entries.

```{r Checking Number of Entries}
which(table(df$PID) != 3)
``` 

In reality, no regulation occurred prior to exposure, so I'm really only interested in datapoints after exposure. I'd hate to exclude someone from analysis just because they are missing data from a point that's irrelevant to these specific analyses. Therefore, I'm going to remove that pre-exposure data from this dataframe and check now that each participant has two entries.

```{r Removing Pre-Exposure}
df_sub <- subset(df, df$Stage != "Pre-Exposure")
(issues <- sort(unique(df$PID))[which(table(df$PID) != 2)])
``` 

We still have a few participants with more or less than two datapoints. Many of the participants with more than two entries are due to errors where we had to restart the qualtrics survey, so those can be removed by identifying the incomplete entries for each participant that was flagged as an issue.

```{r Removing issue rows}
for (i in issues){
  if (any(df_sub$Finished != TRUE & df_sub$PID == i)){
    df_sub <- df_sub[-(which(df_sub$Finished != TRUE & df_sub$PID == i)),] 
  }
}
``` 

Now let's run the check again and see how many participants still do not have 2 points of data.

```{r Checking issue rows}
  which(table(df_sub$PID) != 2)
``` 

Okay, not bad at all, so only A-079 is remaining as an issue.

```{r Cleaning Cleaning Dataframes Section}
  rm(i, issues)
``` 

# ISOLATING RELEVANT VARIABLES  
  
Not all remaining variables are relevant to regulation. Some are physiology. Some are memory. Either way, I'm going to isolate those variables we want. Unfortunately, because the original naming conventions were so poor, I have no real choice other than to specify by index which columns I need, which is pretty susceptible to human error, but we just have to be careful. 

```{r Isolating Relevant variables}  
df_reg <- df_sub[,c(18:19, 878:956, 713:804, 957:1122)]
rm(df_sub)
``` 

Even within the big chunks we cut out, there are superfluous variables. The timing columns are not relevant for these analyses. Entry was too inconsistent to reliably use as a measure due to the conditions in which this data was collected. Therefore, I'm removing them.

```{r Removing Timing Columns}
df_reg <- df_reg[,-c(grep("First.Click", colnames(df_reg)),
                     grep("Last.Click", colnames(df_reg)),
                     grep("Page.Submit", colnames(df_reg)),
                     grep("Click.Count", colnames(df_reg)))]
``` 

# RENAMING COLUMNS

We want to know what the hell we're looking at and these current column names are going to be a major problem. Luckily, the order of the data follows a predictable pattern, so we're going to write new column names so that we can be more exact in our variable calls and such. Here I'm creating an array of the emotion-related questions we ask for each section or event

```{r Specifying Emotion Questions}
EmotionQs <- c(paste0("Emotion", 1:5), 
               paste0("Emotion", 1:5,"Intense"), 
               paste0("Emotion", 1:5,"Reg"), 
               paste0("Emotion", 1:5,"RegDesc"), 
               paste0("Emotion", 1:5,"RegSuccess"))
``` 

Here I'm creating two arrays. Which one is used depends upon what stage the data was asked at. At the Immediate post-exposure stage, we specified a section from which we expected people to recall events. With the Delayed post-exposure, we left it open. Therefore, we need to add stage for immediate, but not delayed.

```{r Specifying Event Questions}
ImmEventQs <- c("CryptDesc", "MachShopDesc", "Keyword")
DelEventQs <- c("Desc", "Keyword")
``` 

Now we're just creating arrays of column names for regulation memory...

```{r Creating Regulation Memory Column Names}
# Creating the variable
EmotionQs.MemReg <- NA

# Populating variable with Emotion Qs
for (i in paste0("0", 1:3,"-")){
  EmotionQs.MemReg <- c(EmotionQs.MemReg, paste0("MemReg_", i, EmotionQs))
}

# Removing the initial variable value
EmotionQs.MemReg <- EmotionQs.MemReg[-1]
```

and immediate post-exposure ...

```{r Specifying Column Names for Emotions Immediately After}
# Creating the variable
EmotionQs.ImmReg <- NA

# Populating the variable with EventQs
for (i in paste0("0", 1:3,"-")){
  EmotionQs.ImmReg <- c(EmotionQs.ImmReg, paste0("ImmReg_", i, ImmEventQs))
}

# Removing the initial variable value
EmotionQs.ImmReg <- EmotionQs.ImmReg[-1]

# Populating variable with Emotion Qs
for (i in paste0("0", 1:3,"-")){
  EmotionQs.ImmReg <- c(EmotionQs.ImmReg, paste0("ImmReg_", i, EmotionQs))
}
```

and delayed post-exposure ...

```{r Specifying Column Names for Emotions One Week Later}
# Creating the variable
EmotionQs.DelReg <- NA

# Populating the variable with EventQs
for (i in paste0("0", 1:6,"-")){
  EmotionQs.DelReg <- c(EmotionQs.DelReg, paste0("DelReg_", i, DelEventQs))
}

# Removing the initial variable value
EmotionQs.DelReg <- EmotionQs.DelReg[-1]

# Populating variable with Emotion Qs
for (i in paste0("0", 1:6,"-")){
  EmotionQs.DelReg <- c(EmotionQs.DelReg, paste0("DelReg_", i, EmotionQs))
}
```

and then assembling all of those into a new concatenated array, which we then apply to the column names of our new regulation dataframe. Then I'm going to sample the first 20 column names to make sure I did it right.

```{r Renaming Columns}
Cols.Reg <- c("PID", "Stage", EmotionQs.MemReg, EmotionQs.ImmReg, EmotionQs.DelReg)
colnames(df_reg) <- Cols.Reg
colnames(df_reg)[1:20]
``` 

```{r Cleaning Renaming Columns}
rm(Cols.Reg, EmotionQs.MemReg, EmotionQs.ImmReg, EmotionQs.DelReg, ImmEventQs, DelEventQs, EmotionQs, i)
```

# PIVOTING DATATFRAME

We need to reformat the dataframe to better fit with what we need to analyze, so we'll apply a series of long-pivots to turn timing and events into single-row-for-single-observation format. 

```{r Pivoting Dataframe Based on Timing}
df_reg <- pivot_longer(data = df_reg,
                              cols = grep("\\_", colnames(df_reg)),
                              names_to = c("Timing", ".value"),
                              names_sep = "\\_",
                              values_drop_na = TRUE)
``` 

```{r Pivoting Dataframe Based on Event}
df_reg <- pivot_longer(data = df_reg,
                              cols = grep("\\-", colnames(df_reg)),
                              names_to = c("Event", ".value"),
                              names_sep = "\\-",
                              values_drop_na = TRUE)
``` 

```{r Pivoting Dataframe Based on Emotion}
colnames(df_reg) <- c("PID", "Stage", "Timing", "Event", "Emotion1_", "Emotion2_", "Emotion3_", "Emotion4_", "Emotion5_", 
                             "Emotion1_Intense", "Emotion2_Intense", "Emotion3_Intense", "Emotion4_Intense", 
                             "Emotion5_Intense", "Emotion1_Reg", "Emotion2_Reg", "Emotion3_Reg", 
                             "Emotion4_Reg", "Emotion5_Reg", "Emotion1_RegDesc", "Emotion2_RegDesc", 
                             "Emotion3_RegDesc", "Emotion4_RegDesc", "Emotion5_RegDesc", 
                             "Emotion1_RegSuccess", "Emotion2_RegSuccess", "Emotion3_RegSuccess", 
                             "Emotion4_RegSuccess", "Emotion5_RegSuccess", "CryptDesc", "MachShopDesc", "Keyword", "Desc")

Cols.Emo <- grep("(Emotion._)$", colnames(df_reg))
names(df_reg)[Cols.Emo] <- paste0(names(df_reg)[Cols.Emo], "Emotion")

df_reg <- pivot_longer(data = df_reg, 
                               cols = starts_with("Emotion"), 
                               names_to = c( "Number", ".value"),
                               names_sep = "_", 
                               names_repair = "unique",
                               values_drop_na = TRUE) 

df_reg$Number <- gsub("Emotion", "", df_reg$Number )
rm(Cols.Emo)
``` 

Some NAs were read as strings, weirdly enough, so we'll just make sure R corrects that. 

```{r Making NAs consistent}
df_reg$Emotion[df_reg$Emotion == "n/a" |
                 df_reg$Emotion == "N/a"] <- NA
``` 

We then have an issue in which sometimes participants wrote two emotions in the same space. We're going to split these into separate observations by first identifying when they occurred

```{r Identifying rows with compound emotions}
rows <- which(str_detect(string =  df_reg$Emotion,
                         pattern = "\\/"))
``` 

and then actually effectively inserting a row with the same emotional intensity score endorsed above. 

```{r Splitting rows with compound emotions}
# Once duplicated, remove the first emotion from each of the originals
for (i in 1:length(rows)){
  df_reg <- add_row(df_reg, df_reg[rows[i],])
  df_reg$Emotion[rows[i]] <- str_replace_all(string = df_reg$Emotion[rows[i]],
                                             pattern = ".*\\/",
                                             replacement = "")
} 

# Remove the second emotion from each of the duplicates
  df_reg$Emotion <- str_replace_all(string = df_reg$Emotion,
                                    pattern = "\\/.*",
                                    replacement = "")
``` 

```{r Cleaning the space}
rm(rows)
```

# QA CHECKS and FURTHER CONSOLIDATION

Consolidating the descriptions people provided of the events they responded to. They are currently separated into columns based upon the section in which they occurred. No row should have data in more than one of these columns, since an event can only occur in one section. The QA check here is just making sure that if a column in any given row has data in it, that the other columns in that row do not have data, and it will output an error if that's the case.

```{r Consolidating Descriptions}
df_reg$Sect <- NA

for (i in 1:length(rownames(df_reg))){
  if (!is.na(df_reg$CryptDesc[i]) & !is.na(df_reg$MachShopDesc[i])){
    print(paste0("Error: Row ", i))
  }
  if (!is.na(df_reg$Desc[i]) & !is.na(df_reg$MachShopDesc[i])){
    print(paste0("Error: Row ", i))
  }  
  if (!is.na(df_reg$CryptDesc[i]) & !is.na(df_reg$Desc[i])){
    print(paste0("Error: Row ", i))
  }    
  if (!is.na(df_reg$CryptDesc[i]) & is.na(df_reg$MachShopDesc[i]) & is.na(df_reg$Desc[i])){
    df_reg$Desc[i] <- df_reg$CryptDesc[i]
    df_reg$Sect[i] <- "Crypt"
  }
  if (is.na(df_reg$CryptDesc[i]) & !is.na(df_reg$MachShopDesc[i]) & is.na(df_reg$Desc[i])){
    df_reg$Desc[i] <- df_reg$MachShopDesc[i]
    df_reg$Sect[i] <- "MachShop"
  }
}

df_reg <- df_reg[,-(grep("^CryptDesc|^MachShopDesc",colnames(df_reg)))]
```

Checking whether there are any rows that have data where it shouldn't be, based upon other data present (e.g., if someone reports regulating an emotion, but doesn't report experiencing an emotion)

```{r QA Checks}
badrows <- NA

for (i in 1:length(rownames(df_reg))){
  if (!is.na(df_reg$RegSuccess[i]) & is.na(df_reg$Emotion[i])){
    print(paste0("Error: Row ", i, " has no emotion, but reports regulation"))
    badrows <- c(badrows, i)
  }
  if (!is.na(df_reg$Reg[i])){
    if (df_reg$Reg[i] == "I did not attempt to change it" & !is.na(df_reg$RegSuccess[i])){
      print(paste0("Error: Row ", i, " reports not regulating, but then has regulation information"))
      badrows <- c(badrows, i)
    }
    if (df_reg$Reg[i] != "I did not attempt to change it" & is.na(df_reg$RegSuccess[i])){
      print(paste0("Error: Row ", i, " reports regulating, but then has no regulation information"))
      badrows <- c(badrows, i)
    }   
  }
}

badrows <- badrows[-1]
df_reg <- df_reg[-badrows[1:(length(badrows)-1)],]
rm(i, badrows)
```

Changing the value of the intensity scores so that they they can be analyzed

```{r Scoring Intensity}
df_reg$Intense[df_reg$Intense == "None at all"] <- 0
df_reg$Intense[df_reg$Intense == "A little"] <- 1
df_reg$Intense[df_reg$Intense == "A moderate amount"] <- 2
df_reg$Intense[df_reg$Intense == "A lot"] <- 3
df_reg$Intense[df_reg$Intense == "A great deal"] <- 4
df_reg$Intense <- as.numeric(df_reg$Intense)

as.data.frame(df_reg[which(is.na(df_reg$Intense)),])
```

Factoring the direction variable

```{r Scoring Direction}
df_reg$Reg[df_reg$Reg == "I attempted to reduce it"] <- "Decrease"
df_reg$Reg[df_reg$Reg == "I attempted to intensify it"] <- "Increase"
df_reg$Reg[df_reg$Reg == "I did not attempt to change it"] <- "Neither" 
df_reg$Reg <- as.factor(df_reg$Reg)

as.data.frame(df_reg[which(is.na(df_reg$Reg)),])
```

Quantifying the success variable

```{r Scoring Success}
df_reg$RegSuccess[df_reg$RegSuccess == "Not at all successful"] <- 0
df_reg$RegSuccess[df_reg$RegSuccess == "A little  successful"] <- 1
df_reg$RegSuccess[df_reg$RegSuccess == "Moderately successful"] <- 2
df_reg$RegSuccess[df_reg$RegSuccess == "Successful"] <- 3
df_reg$RegSuccess[df_reg$RegSuccess == "Very  successful"] <- 4
df_reg$RegSuccess <- as.numeric(df_reg$RegSuccess)
```

# RENAMING COLUMNS

```{r Renaming Columns}
df_reg <- rename(df_reg, c(EventNum = Event,
                           EventKey = Keyword,
                           EventDesc = Desc,
                           EmoNum = Number))
```

# TRANSFORMING VARIABLES

We now want to person-center our primary variables of interest. 

```{r Person Centering and Aggregating}
df_reg <- dplyr::group_by(df_reg, as.factor(PID))
df_reg <- dplyr::mutate(df_reg, 
                    Intense.pmean = mean(Intense, na.rm=T),
                    RegSuccess.pmean = mean(RegSuccess, na.rm=T),
                    Intense.pc = Intense - mean(Intense, na.rm=T),
                    RegSuccess.pc = RegSuccess - mean(RegSuccess, na.rm=T))
df_reg <- ungroup(df_reg)
``` 

and then z-score them. 

```{r Z Scoring Aggregates}   
df_reg <- group_by(df_reg, PID)
df_reg$Intense.pmean.z <- as.numeric(scale(df_reg$Intense.pmean, scale = T, center = T))
df_reg$RegSuccess.pmean.z <- as.numeric(scale(df_reg$RegSuccess.pmean, scale = T, center = T))
df_reg <- ungroup(df_reg)
``` 

```{r Z Scoring Variables}
  df_reg$Intense.z <- as.numeric(scale(df_reg$Intense, scale=T, center=T))
  df_reg$RegSuccess.z <- as.numeric(scale(df_reg$RegSuccess, scale=T, center=T))
  df_reg$Intense.pc.z <- as.numeric(scale(df_reg$Intense.pc, scale=T, center=T))
  df_reg$RegSuccess.pc.z <- as.numeric(scale(df_reg$RegSuccess.pc, scale=T, center=T))
```

# MERGING CLEANED EMOTION DATAFRAMES

Now it's frankly just a series of boring, dataframe mergers, unfortuantely, which will be long and drawn out, so I'm going to skip some of the compentary (see the chunk descriptions for what each is doing). 

## CLEANED EMOTIONS

```{r Reading Cleaned, Lemmatized Emotion .CSV}
df_emo <- read.csv(paste0(Import,"df_emo_lemmatization.csv"),
                   header = T,
                   na.strings = "NA") %>%
          remove_NAs(cols = TRUE, 
                     rows = TRUE) %>%
          .[,-1]
``` 

```{r Converting all emotions to lowercase}
df_reg$Emotion <- tolower(df_reg$Emotion)
df_emo$Emotion <- tolower(df_emo$Emotion)
df_reg$Emotion <- trimws(df_reg$Emotion)
``` 

```{r Merging Emotion Dataframes}
df_reg <- merge(df_reg,
                df_emo,
                by = "Emotion",
                all.x = T)
``` 

```{r Removing duplicate rows}
df_reg <- df_reg %>% 
  distinct()
``` 

```{r Cleaning Emo Space}
rm(df_emo)
```

## NRC LEXICON

```{r Reading in the dictionary}
df_lex <- read.table(paste0(Import,"NRC-VAD-Lexicon.txt"), 
                 header = FALSE, 
                 sep = "^", 
                 dec = ".")
``` 

Unfortunately, the way the data has been read in is extremely messy so now we need to clean it up. Everything is in a single column so we need to isolate the indiviudal components into different columns.

```{r  Saving the target word into its own column}
df_lex$Word <- gsub(pattern = "[^a-zA-Z]",
                replacement = "",
                x = df_lex$V1)
``` 

```{r Removing the target word from the singular column}
df_lex$V1 <- str_replace_all(string = df_lex$V1,
                         pattern = "[a-zA-Z]",
                         replacement = "")
``` 

```{r  Saving the valence score into its own column}
df_lex$Valence <- str_extract(string = df_lex$V1, 
                          pattern = "[[:digit:]]+\\.[[:digit:]]+")
``` 

```{r Removing the valence score from the singular column}
df_lex$V1 <- str_replace(string = df_lex$V1,
                     pattern = "[[:digit:]]+\\.[[:digit:]]+",
                     replacement = "")
``` 

```{r  Saving the arousal score into its own column}
df_lex$Arousal <- str_extract(string = df_lex$V1, 
                          pattern = "[[:digit:]]+\\.[[:digit:]]+")
``` 

```{r Removing the arousal score from the singular column}
df_lex$V1 <- str_replace(string = df_lex$V1,
                     pattern = "[[:digit:]]+\\.[[:digit:]]+",
                     replacement = "")
``` 

```{r  Saving the dominance score into its own column}
df_lex$Dominance <- str_extract(string = df_lex$V1, 
                            pattern = "[[:digit:]]+\\.[[:digit:]]+")
``` 

```{r Getting rid of the singular column}
df_lex <- df_lex[,-1]
``` 

```{r Reading in another dictionary from lexicon as a dataframe}
nrc <- as.data.frame(nrc_emotions)
``` 

```{r Merging the VAD with the NRC}
nrc <- merge(x = df_lex,
             y = nrc,
             by.x = "Word",
             by.y = "term",
             all.x = TRUE)
``` 

```{r Removing the NRC dataframe}
rm(df_lex)
``` 

```{r Z-Scoring NRC}
nrc$Valence_z <- as.numeric(scale(as.numeric(nrc$Valence)))
nrc$Arousal_z <- as.numeric(scale(as.numeric(nrc$Arousal)))
nrc$Dominance_z <- as.numeric(scale(as.numeric(nrc$Dominance)))
``` 

```{r Merging Emotion Dataframes}
df_reg <- merge(df_reg,
                nrc,
                by.x = "EmoMod",
                by.y = "Word",
                all.x = T)
``` 

```{r Cleaning NRC Space}
rm(nrc)
```

## CHECKING MERGES

Ideally, every word people cited would be matched to an NRC entry. There may be cases where R could not find matches due to slight word differences, blank space, misspellings, etc. I'm going to manually review those cases where there was no NRC match just to check that it's not an issue.

```{r Isolating Relevant Rows}
df_reg$EmoMod[!is.na(df_reg$EmoMod) & is.na(df_reg$Valence)] %>%
  unique() %>%
  sort()
```

Not horrible.

```{r Correcting Structures}
df_reg$PID <- as.factor(df_reg$PID)
df_reg$EventNum <- as.factor(df_reg$EventNum)
df_reg$EmoNum <- as.factor(df_reg$EmoNum)
df_reg$Timing <- as.factor(df_reg$Timing)
df_reg$RegSuccess <- as.numeric(df_reg$RegSuccess)
df_reg$Intense <- as.numeric(df_reg$Intense)
df_reg$Valence <- as.numeric(df_reg$Valence)
df_reg$Arousal <- as.numeric(df_reg$Arousal)
df_reg$Dominance <- as.numeric(df_reg$Dominance)
df_reg$EmoMod <- tolower(df_reg$EmoMod)
df_reg$EmoMod <- tolower(df_reg$EmoMod)
``` 

```{r Z-Scoring Qualtrics Events}
df_reg$Intense_z <- as.numeric(scale(df_reg$Intense))
df_reg$RegSuccess_z <- as.numeric(scale(df_reg$RegSuccess))
``` 

```{r Creating a Cateogry Superfactor}
df_reg$EmoCat <- NA
for (i in 1:nrow(df_reg)){
  cats <- NA
  if (df_reg$anger[i] == 1 & !is.na(df_reg$anger[i])){
    cats <- c(cats, "Anger")
  }
  if (df_reg$anticipation[i] == 1 & !is.na(df_reg$anticipation[i])){
    cats <- c(cats, "Anticipation")
  }
  if (df_reg$disgust[i] == 1 & !is.na(df_reg$disgust[i])){
    cats <- c(cats, "Disgust")
  }
  if (df_reg$fear[i] == 1 & !is.na(df_reg$fear[i])){
    cats <- c(cats, "Fear")
  }
  if (df_reg$joy[i] == 1 & !is.na(df_reg$joy[i])){
    cats <- c(cats, "Joy")
  }
  if (df_reg$sadness[i] == 1 & !is.na(df_reg$sadness[i])){
    cats <- c(cats, "Sadness")
  }
  if (df_reg$surprise[i] == 1 & !is.na(df_reg$surprise[i])){
    cats <- c(cats, "Surprise")
  }
  if (df_reg$trust[i] == 1 & !is.na(df_reg$trust[i])){
    cats <- c(cats, "Trust")
  }
  if (length(cats) > 1){
    cats <- cats[-1]
    df_reg$EmoCat[i] <- paste(cats, collapse =", ")
  }
}
```

Participants were shown their previously noted events at a later date and asked to recall their emotional experiences. However. because they did not enter it themselves, Qualtrics didn't export it. Therefore, I need to copy the recall info from when it was initially written which is what I'm doing here. 

```{r Copying the recall info from when I was initially written}
for (i in unique(sort(df_reg$PID))){
  for (j in unique(sort(df_reg$EventNum))){
    df_reg$EventKey[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "MemReg"] <- df_reg$EventKey[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "ImmReg"][1]
    df_reg$EventDesc[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "MemReg"] <- df_reg$EventDesc[df_reg$PID == i & df_reg$EventNum == j & df_reg$Timing == "ImmReg"][1]
  }
}
```

# MERGING CODING RESPONSES 

Coding includes the process of having trained independent raters review regulatory free-responses and identify which strategies were used in each. There was a lot of data and we couldn't do it in one sitting, so we broke the data into individual .csv's to make the goals (i.e., how many observations to review and when to review them by) more organized and easier to achieve.Now, we need to merge them though.

```{r Reading Cleaned Coded .CSV}
  df_coding <- rbind(read.csv(paste0(Import,"coding_round1.csv"),
                              header = T,
                              na.strings = "NA"),
                     read.csv(paste0(Import,"coding_round2.csv"),
                              header = T,
                              na.strings = "NA"),
                     read.csv(paste0(Import,"coding_round3.csv"),
                              header = T,
                              na.strings = "NA"))
``` 

```{r Merging Coded Dataframes}
  df_reg <- merge(df_reg,
                  df_coding,
                  by.x = c("EmoMod", "Reg", "RegDesc", "EventKey", "EventDesc", "Intense"),
                  by.y = c("Emotion", "Reg", "RegDesc", "EventKey", "EventDesc", "Intense"),
                  all = T)
``` 

```{r Reading Practice Coded .CSV}
  df_coding <- read.csv(paste0(Import,"coding_round4.csv"),
                              header = T,
                              na.strings = "NA") 
``` 

```{r Correcting Terminology}
  df_coding$Reg[df_coding$Reg == "Reduce"] <- "Decrease"
``` 

```{r Merging Coded Dataframes}
  for (i in 1:nrow(df_coding)){
    target <- which(df_reg$Intense == df_coding$Intense[i] &
                      df_reg$Reg == df_coding$Reg[i] &
                      df_reg$RegDesc == df_coding$RegDesc[i] &
                      df_reg$EventDesc == df_coding$EventDesc[i] &
                      df_reg$EventDesc == df_coding$EventDesc[i] & 
                      df_reg$EmoMod == df_coding$Emotion[i])
    
    if (length(target) == 0){
      paste("Row", i, "had no matches in the primary dataframe")
    }
    
    if (length(target) > 1){
      paste("Row", i, "had multiple matches in the primary dataframe")
    }
    
    if (length(target) == 1){
      df_reg$Attention.Deployment[target] <- df_coding$Attention.Deployment[i] 
      df_reg$Response.Modulation[target] <- df_coding$Response.Modulation[i] 
      df_reg$Reappraisal[target] <- df_coding$Reappraisal[i] 
      df_reg$Correct[target] <- df_coding$Correct[i]
    }
  }
``` 

```{r Cleaning our space}
rm(df_coding, i, j, cats, target)               
``` 

```{r Removing duplicate rows}
df_reg <- df_reg %>% 
          distinct() %>%
          remove_NAs()
```

### Preparing for Export

```{r Checking structure}
str(df_reg)
``` 

```{r Restructuing factors}
df_reg$EmoMod <- as.factor(df_reg$EmoMod)
df_reg$Stage <- as.factor(df_reg$Stage)
df_reg$Sect <- as.factor(df_reg$Sect)
``` 

```{r Releveling Reg}
df_reg$Reg <- as.factor(as.character(df_reg$Reg)) %>%
  relevel(., ref = "Neither")
``` 

```{r Checking Regs levels}
levels(df_reg$Reg)
```

# INSERTING PARTICIPANT LEVEL SUPPLEMENTARY DATA

Our next step should be to pivot the dataframe, but before I do that I want to insert the relevant participant-level variables so that we're not having R do more work than we need it to. These will include Conditions and Measures, RAT scores, Fear Ratings, Demographics information, and experiential information. I'm starting with measures first: 

## MEASURES

Not all of the variables in the full dataframe are relevant to the validated measures, so I identified the ones that were. Whenever you see `[,]` following a dataframe it's identifying specific rows, columns or cells in the dataframe. The first place refers to row positions. They can refer to one row or multiple (if multiple, we need to concatenate them together using the `c()` command). When left blank, we are telling R to use all of the rows in the dataframe. The place after the comma is where we note columns. The numbers refer to their corresponding position in the dataframe. I hand to identify these by hand since the names are currently gibberish. So we are essentially telling R to create a new dataframe named "df_measures" that only contains these specific columns. 

```{r Separating dataframes into sets}
df_measures <- df[,c(18:19, 542:646)]
```

...and then removing any rows that don't have "Pre-Exposure" under the Stage column, since there were no measure questions asked after that stage.

```{r Removing Empty Rows of Data}
df_measures <- subset(df_measures, df_measures$Stage == "Pre-Exposure")
``` 

I know I've found more eloquent ways to assign numeric values to categorical variables in the past, but this'll have to do the trick now.

```{r SCORING BDI}
# Assigning Numeric Values to BDI Responses}
df_measures$BDI.01[df_measures$BDI.01 == "I do not feel sad."] <- 0
df_measures$BDI.01[df_measures$BDI.01 == "I feel sad."] <- 1
df_measures$BDI.01[df_measures$BDI.01 == "I am sad all the time and I can't snap out of it."] <- 2
df_measures$BDI.01[df_measures$BDI.01 == "I am so sad and unhappy that I can't stand it."] <- 3
df_measures$BDI.02[df_measures$BDI.02 == "I am not particularly pessimistic or discouraged about the future."] <- 0
df_measures$BDI.02[df_measures$BDI.02 == "I feel discouraged about the future."]  <- 1
df_measures$BDI.02[df_measures$BDI.02 == "I feel I have nothing to look forward to."]  <- 2
df_measures$BDI.02[df_measures$BDI.02 == "I feel the future is hopeless and that things cannot improve."]  <- 3
df_measures$BDI.03[df_measures$BDI.03 == "I do not feel like a failure."] <- 0
df_measures$BDI.03[df_measures$BDI.03 == "I feel I have failed more than the average person."]  <- 1
df_measures$BDI.03[df_measures$BDI.03 == "As I look back on my life, all I can see is a lot of failures."]  <- 2
df_measures$BDI.03[df_measures$BDI.03 == "I feel I am a complete failure as a person."] <- 3
df_measures$BDI.04[df_measures$BDI.04 == "I am not particularly dissatisfied."] <- 0
df_measures$BDI.04[df_measures$BDI.04 == "I don't enjoy things the way I used to."] <- 1
df_measures$BDI.04[df_measures$BDI.04 == "I don't get satisfaction out of anything anymore."] <- 2
df_measures$BDI.04[df_measures$BDI.04 == "I am dissatisfied with everything."] <- 3
df_measures$BDI.05[df_measures$BDI.05 == "I don't feel particularly guilty."] <- 0
df_measures$BDI.05[df_measures$BDI.05 == "I feel guilty over many things I have done or should have done."] <- 1
df_measures$BDI.05[df_measures$BDI.05 == "I feel quite guilty most of the time."] <- 2
df_measures$BDI.05[df_measures$BDI.05 == "I feel guilty all of the time."] <- 3
df_measures$BDI.06[df_measures$BDI.06 == "I don't feel disappointed in myself."] <- 0
df_measures$BDI.06[df_measures$BDI.06 == "I am disappointed in myself."] <- 1
df_measures$BDI.06[df_measures$BDI.06 == "I am disgusted with myself."] <- 2
df_measures$BDI.06[df_measures$BDI.06 == "I hate myself."] <- 3
df_measures$BDI.07[df_measures$BDI.07 == "I have not lost interest in other people."] <- 0
df_measures$BDI.07[df_measures$BDI.07 == "I am less interested in other people than I used to be."] <- 1
df_measures$BDI.07[df_measures$BDI.07 == "I have lost most of my interest in other people."] <- 2
df_measures$BDI.07[df_measures$BDI.07 == "I have lost all of my interest in other people."] <- 3
df_measures$BDI.08[df_measures$BDI.08 == "I make decisions about as well as I ever could."] <- 0
df_measures$BDI.08[df_measures$BDI.08 == "I put off making decisions more than I used to."] <- 1
df_measures$BDI.08[df_measures$BDI.08 == "I have greater difficulty in making decisions more than I used to."] <- 2
df_measures$BDI.08[df_measures$BDI.08 == "I can't make any decisions at all anymore."] <- 3
df_measures$BDI.09[df_measures$BDI.09 == "I don't feel that I look any worse than I used to."] <- 0
df_measures$BDI.09[df_measures$BDI.09 == "I am worried that I am looking old or unattractive."] <- 1
df_measures$BDI.09[df_measures$BDI.09 == "I feel that there are permanent changes in my appearance and they make me look unattractive."] <- 2
df_measures$BDI.09[df_measures$BDI.09 == "I believe that I look ugly."] <- 3
df_measures$BDI.10[df_measures$BDI.10 == "I can work about as well as before."] <- 0
df_measures$BDI.10[df_measures$BDI.10 == "It takes extra effort to get started at doing something."] <- 1
df_measures$BDI.10[df_measures$BDI.10 == "I have to push myself very hard to do anything."] <- 2
df_measures$BDI.10[df_measures$BDI.10 == "I can't do any work at all."] <- 3
df_measures$BDI.11[df_measures$BDI.11 == "I don't get more tired than usual."] <- 0
df_measures$BDI.11[df_measures$BDI.11 == "I get tired more easily than I used to."] <- 1
df_measures$BDI.11[df_measures$BDI.11 == "I get tired from doing almost anything."] <- 2
df_measures$BDI.11[df_measures$BDI.11 == "I get too tired to do anything."] <- 3
df_measures$BDI.12[df_measures$BDI.12 == "My appetite is no worse than usual."] <- 0
df_measures$BDI.12[df_measures$BDI.12 == "My appetite is not as good as it used to be."] <- 1
df_measures$BDI.12[df_measures$BDI.12 == "My appetite is much worse now."] <- 2
df_measures$BDI.12[df_measures$BDI.12 == "I have no appetite at all anymore."] <- 3

# Restructuring BDI Variables as Numeric}
BDI.Cols <- grep("BDI", colnames(df_measures))
for (i in BDI.Cols){
  df_measures[,i] <- as.numeric(df_measures[,i])
}

# Calculating BDI}
for (i in 1:length(rownames(df_measures))){
  df_measures$BDI_Total[i] <- sum(df_measures[i,BDI.Cols])
}

# Removing BDI We No Longer Need}
rm(BDI.Cols, i)

``` 

```{r SCORING ERQ}
# Assigning Numeric Values to ERQ Responses}
ERQ.Cols <- grep("ERQ", colnames(df_measures))
for (i in ERQ.Cols){
  for (j in 1:length(rownames(df_measures))){
    if (df_measures[j,i] == "Strongly disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 1
    if (df_measures[j,i] == "Disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 2
    if (df_measures[j,i] == "Somewhat disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 3
    if (df_measures[j,i] == "Neither agree nor disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 4
    if (df_measures[j,i] == "Somewhat agree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 5
    if (df_measures[j,i] == "Agree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 6
    if (df_measures[j,i] == "Strongly agree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 7    
  }
}

# Restructuring ERQ Variables as Numeric}
for (i in ERQ.Cols){
  df_measures[,i] <- as.numeric(df_measures[,i])
}

# Calculating ERQ}
df_measures$ERQ_CogReap <- df_measures$ERQ.01 + df_measures$ERQ.03 + 
  df_measures$ERQ.05 + df_measures$ERQ.07 + 
  df_measures$ERQ.08 + df_measures$ERQ.10

df_measures$ERQ_ExpSup <- df_measures$ERQ.02 + df_measures$ERQ.04 + 
  df_measures$ERQ.06 + df_measures$ERQ.09

# Removing ERQ We No Longer Need}
rm(ERQ.Cols, i, j)

``` 

```{r SCORING IUS}
# Assigning Numeric Values to IUS Responses}
IUS.Cols <- grep("IUS", colnames(df_measures))
for (i in IUS.Cols){
  for (j in 1:length(rownames(df_measures))){
    if (df_measures[j,i] == "Not at all characteristic of me" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 1
    if (df_measures[j,i] == "A little characteristic of me" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 2
    if (df_measures[j,i] == "Somewhat characteristic of me" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 3
    if (df_measures[j,i] == "Very characteristic of me" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 4
    if (df_measures[j,i] == "Entirely characteristic of me" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 5
  }
}

# Restructuring IUS Variables as Numeric}
for (i in IUS.Cols){
  df_measures[,i] <- as.numeric(df_measures[,i])
}

# Calculating IUS}
for (i in 1:length(rownames(df_measures))){
  df_measures$IUS_Total[i] <- sum(df_measures[i,IUS.Cols])
  df_measures$IUS_F1[i] <- sum(df_measures[i,IUS.Cols[-c(4, 5, 6, 7, 8, 10, 11, 18, 19, 21, 26, 27)]])
  df_measures$IUS_F2[i] <- sum(df_measures[i,IUS.Cols[c(4, 5, 6, 7, 8, 10, 11, 18, 19, 21, 26, 27)]])
}

# Removing IUS We No Longer Need}
rm(IUS.Cols, i, j)

``` 

```{r SCORING STAI}
# Assigning Numeric Values to STAI Responses}
STAI.Cols <- grep("STAI", colnames(df_measures))
for (i in STAI.Cols){
  for (j in 1:length(rownames(df_measures))){
    if (df_measures[j,i] == "Not at all" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 1
    if (df_measures[j,i] == "Somewhat" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 2
    if (df_measures[j,i] == "Moderately so" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 3
    if (df_measures[j,i] == "Very much so" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 4
  }
}

# Restructuring STAI Variables as Numeric}
for (i in STAI.Cols){
  df_measures[,i] <- as.numeric(df_measures[,i])
}

# Reverse Scoring STAI}
STAI.Cols.r <- STAI.Cols[c(1,2,5,8,10,11,15,16,19,20,21,26,27,30,31,35,36,39)]
for (i in STAI.Cols.r){
  df_measures[,i] <- 5 - df_measures[,i]
}

# Calculating STAI}
for (i in 1:length(rownames(df_measures))){
  df_measures$STAI_State[i] <- sum(df_measures[i, STAI.Cols[-c(1:20)]])
  df_measures$STAI_Trait[i] <- sum(df_measures[i, STAI.Cols[c(1:20)]])
}

# Removing STAI We No Longer Need}
rm(STAI.Cols, STAI.Cols.r, i, j)

``` 

```{r SCORING IRQ}
# Assigning Numeric Values to IRQ Responses}
IRQ.Cols <- grep("IRQ", colnames(df_measures))
for (i in IRQ.Cols){
  for (j in 1:length(rownames(df_measures))){
    if (df_measures[j,i] == "Strongly disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 1
    if (df_measures[j,i] == "Disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 2
    if (df_measures[j,i] == "Somewhat disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 3
    if (df_measures[j,i] == "Neither agree nor disagree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 4
    if (df_measures[j,i] == "Somewhat agree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 5
    if (df_measures[j,i] == "Agree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 6
    if (df_measures[j,i] == "Strongly agree" & !is.na(df_measures[j,i]))
      df_measures[j,i] <- 7   
  }
}

# Restructuring IRQ Variables as Numeric}
for (i in IRQ.Cols){
  df_measures[,i] <- as.numeric(df_measures[,i])
}

# Calculating IRQ}
for (i in 1:length(rownames(df_measures))){
  df_measures$IRQ_NT[i] <- sum(df_measures[i, IRQ.Cols[c(1:4)]])
  df_measures$IRQ_NE[i] <- sum(df_measures[i, IRQ.Cols[c(5:8)]])
  df_measures$IRQ_PT[i] <- sum(df_measures[i, IRQ.Cols[c(9:12)]])
  df_measures$IRQ_PE[i] <- sum(df_measures[i, IRQ.Cols[c(13:16)]])
}

# Removing IRQ We No Longer Need}
rm(IRQ.Cols, i, j)
``` 

```{r EXPORTING DATAFRAME}
df_measures <- df_measures[,-2] 
write.csv(df_measures,
          file = paste0(Export, "df_measures.csv"), 
          na = "N/A")
``` 

We don't need all of individual elements of each measure, just the composites, so I'm going to isolate those.

```{r Isolating Measures}
df_suppl <- df_measures[,c(1,107:118)]

``` 

```{r Cleaning Measures}
rm(df_measures)
``` 

## DEMOGRAPHICS

Doing the same for demographics:

```{r SEPARATING DATAFRAMES}
# Separating dataframes into sets
df_demo <- df[,c(18:19, 666:673)]

# Removing Empty Rows of Data
df_demo <- subset(df_demo, df_demo$Stage == "Pre-Exposure")
``` 

We left gender open ended which was a little bit of a mistake so here I'm trying to categorize all of the possible responses into one of four categories...
```{r Standardizing Gender}
df_demo$Gender[df_demo$Gender == "Female" | df_demo$Gender == "female" | 
                 df_demo$Gender == "femal" | df_demo$Gender == "Female Cisgendered" |
                 df_demo$Gender == "Femal" | df_demo$Gender == "woman" | 
                 df_demo$Gender == "Woman" | df_demo$Gender == "women" |
                 df_demo$Gender == "She/Her" | df_demo$Gender == "FEMALE" |
                 df_demo$Gender == "F" | 
                 (df_demo$Gender == "STRAIGHT" & df_demo$Sex == "Female") ] <- 0
df_demo$Gender[df_demo$Gender == "Male" | df_demo$Gender == "male" | 
                 df_demo$Gender == "MALE" | df_demo$Gender == "He/Him" |
                 df_demo$Gender == "Transgender Male"   ] <- 1
df_demo$Gender[df_demo$Gender == "NonBinary" | df_demo$Gender == "Gender non-conforming " | 
                 df_demo$Gender == "genderfluid" | df_demo$Gender == "pangender" ] <- 2
df_demo$Gender[df_demo$Gender == "Prefer not to specify " ] <- 3
```

...and then naming those categories. 

```{r Creating a categorical Gender Variable}
df_demo$Gender.cat[df_demo$Gender == "0" ] <- "Female"  
df_demo$Gender.cat[df_demo$Gender == "1" ] <- "Male"  
df_demo$Gender.cat[df_demo$Gender == "2" ] <- "Non-Binary"    
df_demo$Gender.cat[df_demo$Gender == "3" ] <- "N/A"
```

R won't understand the ranked order inherent to some of the points in this factor, so we're adding a numeric value to this variable so that the order can be understood by R

```{r Creating a Ranked Factor Variable for Education}
df_demo$Education.Num[df_demo$Education.Cat == "Some high school"] <- 0
df_demo$Education.Num[df_demo$Education.Cat == "High school degree or GED"] <- 1
df_demo$Education.Num[df_demo$Education.Cat == "Some college"] <- 2
df_demo$Education.Num[df_demo$Education.Cat == "Vocational / technical / trade training"] <- 3
df_demo$Education.Num[df_demo$Education.Cat == "College degree (BA, BS, etc.)"] <- 4
df_demo$Education.Num[df_demo$Education.Cat == "Some graduate school"] <- 5
df_demo$Education.Num[df_demo$Education.Cat == "Graduate school degree (MA, MS, PhD, etc.)"] <- 6
```

Same thing here. 

```{r Creating a Ranked Factor Variable for Income}
df_demo$Income.Num[df_demo$Income.Cat == "under $15,000"] <- 0
df_demo$Income.Num[df_demo$Income.Cat == "$15,001 - $25,000"] <- 1
df_demo$Income.Num[df_demo$Income.Cat == "$25,001 - $35,000"] <- 2
df_demo$Income.Num[df_demo$Income.Cat == "$35,001 - $50,000"] <- 3
df_demo$Income.Num[df_demo$Income.Cat == "$50,001 - $75,000"] <- 4
df_demo$Income.Num[df_demo$Income.Cat == "$75,001 - $100,000"] <- 5
df_demo$Income.Num[df_demo$Income.Cat == "$100,001 - $150,000"] <- 6
df_demo$Income.Num[df_demo$Income.Cat == "over $150,000"] <- 7
``` 

```{r EXPORTING DATAFRAME}
df_demo <- df_demo[,-2]
write.csv(df_demo,
          file = paste0(Export, "df_demo.csv"), 
          na = "N/A")
```

and now we'll merge it to the regulation dataframe

```{r Merging Demographics}
df_suppl <- merge(df_suppl,
                  df_demo,
                  by = "PID",
                  all.x = T)
``` 

```{r Cleaning Demographics}
rm(df_demo)
``` 

## EXPERIENCE

Doing the same for Experience:

```{r Separating dataframes into sets}
df_exp <- df[,c(18:19, 647:665, 805:838, 1186:1211)]
``` 

We asked everyone whether they had been to TBTW in the past during screening AND at baseline, so that's what this value captures. I'm just taking whatever value individuals indicated at baseline and carrying it forward to later stages.

```{r Filling in missing TBTW spaces}
for (i in sort(unique(df_exp$PID))){
  df_exp$TBTW[df_exp$PID == i & df_exp$Stage != "Pre-Exposure"] <- df_exp$TBTW[df_exp$PID == i & df_exp$Stage == "Pre-Exposure"]
}
df_exp <- rename(df_exp, TBTW.Previous = TBTW)
df_exp <- rename(df_exp, TBTW.Confirm = TBTW.Check)
``` 

We captured anticipation of positive and negative emotions three times throughout the process. Each time the question was asked, we were measuring the same time point, but testing how memory of anticipation might change over time, so the question wasn't identical, but was rephrased so that it was targeting the same feelings as the time at which it was asked changed. As such, we want to move this variable into the same column.

```{r Consolidating Anticipation Responses}
for (i in 1:length(rownames(df_exp))){
  if (df_exp$Stage[i] == "Pre-Exposure")
    df_exp$Pos.Anticipate[i] <- df_exp$Pos.Anticipate[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$Pos.Anticipate[i] <- df_exp$IPE...Pos.Anticipate[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Pos.Anticipate[i] <- df_exp$Pos.Anticipat[i]
  if (df_exp$Stage[i] == "Pre-Exposure")
    df_exp$Neg.Anticipate[i] <- df_exp$Neg.Anticipate[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$Neg.Anticipate[i] <- df_exp$IPE...Neg.Anticipate[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Neg.Anticipate[i] <- df_exp$Neg.Anticipat[i]
}
```

Same thing with the Fear Before responses.

```{r Consolidating Fear Before Responses}
for (i in 1:length(rownames(df_exp))){
  if (df_exp$Stage[i] == "Pre-Exposure")
    df_exp$Fear.Before[i] <- df_exp$Fear.Before[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$Fear.Before[i] <- df_exp$IPE...Fear.Before[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Fear.Before[i] <- df_exp$Fear.Before.1[i]
}
```

Same thing with the Fear During and After responses (though we obviously didn't capture those before people went in.

```{r Consolidating Fear During and After Responses}
for (i in 1:length(rownames(df_exp))){
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$Fear.During[i] <- df_exp$IPE...Fear.During[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Fear.During[i] <- df_exp$Fear.During[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$Fear.After[i] <- df_exp$IPE...Fear.After[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Fear.After[i] <- df_exp$Fear.After[i]
}
```

```{r Consolidating Memory & Fear Questions}
df_exp$S1.Memory <- NA
df_exp$S2.Memory <- NA
df_exp$S3.Memory <- NA
df_exp$S1.Fear <- NA
df_exp$S2.Fear <- NA
df_exp$S3.Fear <- NA
df_exp$Set.Memory <- NA

for (i in 1:length(rownames(df_exp))){
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$S1.Memory[i] <- df_exp$IPE...S1.Memory[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$S2.Memory[i] <- df_exp$IPE...S2.Memory[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$S3.Memory[i] <- df_exp$IPE...S3.Memory[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$S1.Fear[i] <- df_exp$IPE...S1.Fear[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$S2.Fear[i] <- df_exp$IPE...S2.Fear[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$S3.Fear[i] <- df_exp$IPE...S3.Fear[i]
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$Set.Memory[i] <- df_exp$IPE...Set.Memory[i]  
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$S1.Memory[i] <- df_exp$OWPE...S1.Memory[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$S2.Memory[i] <- df_exp$OWPE...S2.Memory[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$S3.Memory[i] <- df_exp$OWPE...S3.Memory[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$S1.Fear[i] <- df_exp$OWPE...S1.Fear[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$S2.Fear[i] <- df_exp$OWPE...S2.Fear[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$S3.Fear[i] <- df_exp$OWPE...S3.Fear[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Set.Memory[i] <- df_exp$OWPE...Set.Memory[i]  
}
```

```{r Consolidating Haunted House Questions}
for (i in 1:length(rownames(df_exp))){
  if (df_exp$Stage[i] == "Immediate Post-Exposure")
    df_exp$HH.Before[i] <- df_exp$IPE...HH.Before[i]
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$HH.Enjoy[i] <- df_exp$OWPE...HH.Enjoy[i]
}
```

```{r Consolidating Information Questions}
for (i in 1:length(rownames(df_exp))){
  if (df_exp$Stage[i] == "One Week Post-Exposure")
    df_exp$Information[i] <- df_exp$OWPE...Information[i]
}
``` 

```{r RENAMING VARIABLES}
# Renaming Social Support
df_exp <- rename(df_exp, PT5.Support = IPE...PT5.Support)
df_exp <- rename(df_exp, PT5.Close = IPE...PT5.Close)
df_exp <- rename(df_exp, PT5.Relation = IPE...PT5.Relation)
df_exp <- rename(df_exp, PT4.Support = IPE...PT4.Support)
df_exp <- rename(df_exp, PT4.Close = IPE...PT4.Close)
df_exp <- rename(df_exp, PT4.Relation = IPE...PT4.Relation)
df_exp <- rename(df_exp, PT3.Support = IPE...PT3.Support)
df_exp <- rename(df_exp, PT3.Close = IPE...PT3.Close)
df_exp <- rename(df_exp, PT3.Relation = IPE...PT3.Relation)
df_exp <- rename(df_exp, PT2.Support = IPE..PT2.Support)
df_exp <- rename(df_exp, PT2.Close = IPE...PT2.Close)
df_exp <- rename(df_exp, PT2.Relation = IPE...PT2.Relation)
df_exp <- rename(df_exp, PT1.Support = IPE..PT1.Support)
df_exp <- rename(df_exp, PT1.Close = IPE...PT1.Close)
df_exp <- rename(df_exp, PT1.Relation = IPE...PT1.Relation)
df_exp <- rename(df_exp, Social.Support = IPE...Social.Support )
df_exp <- rename(df_exp, Peer.Number = IPE...Peer.Number)
df_exp <- rename(df_exp, Peer.Presence = IPE...Peer.Presence)

# Renaming Confound Questions
df_exp <- rename(df_exp, Discuss = OWPE...Discuss)
df_exp <- rename(df_exp, Discuss.Times = OWPE...Discuss.Times)
df_exp <- rename(df_exp, Search = OWPE...Search)
df_exp <- rename(df_exp, Search.Times = OWPE...Search.Time)
df_exp <- rename(df_exp, Phobias = IPE...Phobias)
df_exp <- rename(df_exp, Phobias.Desc = IPE...Phobias.Desc.)  
df_exp <- rename(df_exp, HH.Compare = IPE...HH.Compare)

# Renaming Motivations
df_exp <- rename(df_exp, Motive.Payment = Motivations_1)
df_exp <- rename(df_exp, Motive.Thrill = Motivations_2)
df_exp <- rename(df_exp, Motive.Novelty = Motivations_3)
df_exp <- rename(df_exp, Motive.Challenge = Motivations_4)
df_exp <- rename(df_exp, Motive.Peers = Motivations_5)
df_exp <- rename(df_exp, Motive.Science = Motivations_6)
df_exp <- rename(df_exp, Motive.Bored = Motivations_7)

# Removing Columns w/ Unorganized Data
df_exp <- subset(df_exp, 
                 select= c("PID", "Stage", "TBTW.Previous", "TBTW.Confirm", "Pos.Anticipate", "Neg.Anticipate", "Fear.Before",
                           "Fear.During", "Fear.After", "S1.Fear", "S1.Memory", "S2.Fear", "S2.Memory", "S3.Fear", "S3.Memory",
                           "Set.Memory", "Peer.Presence", "Peer.Number", "Social.Support", "PT1.Relation", "PT1.Close", "PT1.Support", 
                           "PT2.Relation", "PT2.Close", "PT2.Support", "PT3.Relation", "PT3.Close", "PT3.Support", "PT4.Relation", 
                           "PT4.Close", "PT4.Support", "PT5.Relation", "PT5.Close", "PT5.Support", "Startle", "HH.Before", "HH.Compare", 
                           "HH.Times", "HH.Enjoy","Fear.Enjoy", "Phobias", "Phobias.Desc", "Discuss", "Discuss.Times", "Search", 
                           "Search.Times", "Motive.Payment", "Motive.Thrill", "Motive.Novelty", "Motive.Challenge", "Motive.Peers", 
                           "Motive.Science", "Motive.Bored", "Information", "Sources")) 

``` 

```{r Scoring Anticipation Variables}
Anticip.Cols <- grep("Anticipate", colnames(df_exp))
for (i in Anticip.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (df_exp[j,i] == "None at all")
        df_exp[j,i] <- 0
      if (df_exp[j,i] == "A little")
        df_exp[j,i] <- 1
      if (df_exp[j,i] == "A moderate amount")
        df_exp[j,i] <- 2
      if (df_exp[j,i] == "A lot")
        df_exp[j,i] <- 3
      if (df_exp[j,i] == "A great deal")
        df_exp[j,i] <- 4
    }
  }
}
```

```{r Restructuring Anticipation Variables as Numeric}
for (i in Anticip.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Anticpation Variables}
rm(Anticip.Cols)
```

```{r Scoring Fear Variables}
Fear.Cols <- grep(("Fear"), colnames(df_exp))
Fear.Cols <- Fear.Cols[-c(7)]
for (i in Fear.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (df_exp[j,i] == "Not at all fearful")
        df_exp[j,i] <- 0
      if (df_exp[j,i] == "A little fearful")
        df_exp[j,i] <- 1
      if (df_exp[j,i] == "Moderately fearful")
        df_exp[j,i] <- 2
      if (df_exp[j,i] == "Very fearful")
        df_exp[j,i] <- 3
      if (df_exp[j,i] == "Extremely fearful")
        df_exp[j,i] <- 4
    }
  }
}
```

```{r Restructuring Fear Variables as Numeric}
for (i in Fear.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Fear Variables}
rm(Fear.Cols)
```

```{r Scoring  Variables}
Memory.Cols <- grep((".Memory"), colnames(df_exp))
Memory.Cols <- Memory.Cols[-c(7)]
for (i in Memory.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (df_exp[j,i] == "Not at all vivid")
        df_exp[j,i] <- 0
      if (df_exp[j,i] == "A little vivid")
        df_exp[j,i] <- 1
      if (df_exp[j,i] == "Moderately vivid")
        df_exp[j,i] <- 2
      if (df_exp[j,i] == "Very vivid")
        df_exp[j,i] <- 3
      if (df_exp[j,i] == "Extremely vivid")
        df_exp[j,i] <- 4
    }
  }
}
```

```{r Restructuring Memory Variables as Numeric}
for (i in Memory.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Memory Variables}
rm(Memory.Cols)
```

```{r Scoring Support Variables}
Support.Cols <- grep(("Social.Support"), colnames(df_exp))
for (i in Support.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (df_exp[j,i] == "Definitely not")
        df_exp[j,i] <- 0
      if (df_exp[j,i] == "Probably not")
        df_exp[j,i] <- 1
      if (df_exp[j,i] == "Probably yes")
        df_exp[j,i] <- 2
      if (df_exp[j,i] == "Definitely yes")
        df_exp[j,i] <- 3
    }
  }
}
```

```{r Restructuring Support Variables as Numeric}
for (i in Support.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```
  
```{r Removing Support Variables}
rm(Support.Cols)
```

```{r Scoring Participant Variables}
Close.Cols <- grep((".Close"), colnames(df_exp))
PT.Cols <- NA
for (i in 1:length(Close.Cols)){
  PT.Cols <- sort(c(PT.Cols, Close.Cols[i], (Close.Cols[i] + 1)))
}
```

```{r Removing Close Variables}
rm(Close.Cols)
```

```{r Scoring Pt Variable}
for (i in PT.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (grepl("Not at all", df_exp[j,i]))
        df_exp[j,i] <- 0
      if (grepl("A little", df_exp[j,i]))
        df_exp[j,i] <- 1
      if (grepl("Moderately", df_exp[j,i]))
        df_exp[j,i] <- 2
      if (grepl("Very", df_exp[j,i]))
        df_exp[j,i] <- 3
      if (grepl("Extremely", df_exp[j,i]))
        df_exp[j,i] <- 4      
    }
  }
}
```

```{r Restructuring Participant Variables as Numeric}
for (i in PT.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Participant Variables}
rm(PT.Cols)
```

```{r Scoring Startle Variables}
Startle.Cols <- grep(("Startle"), colnames(df_exp))
for (i in Startle.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (grepl("Not at all", df_exp[j,i]))
        df_exp[j,i] <- 0
      if (grepl("A little", df_exp[j,i]))
        df_exp[j,i] <- 1
      if (grepl("Moderately", df_exp[j,i]))
        df_exp[j,i] <- 2
      if (grepl("Very", df_exp[j,i]))
        df_exp[j,i] <- 3
      if (grepl("Extremely", df_exp[j,i]))
        df_exp[j,i] <- 4      
    }
  }
}
```

```{r Restructuring Startle Variables as Numeric}
for (i in Startle.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Startle Variables}
rm(Startle.Cols)
```

```{r Scoring Compare Variables}
Compare.Cols <- grep(("Compare"), colnames(df_exp))
for (i in Compare.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (grepl("Much less scary", df_exp[j,i]))
        df_exp[j,i] <- 0
      if (grepl("Less scary", df_exp[j,i]))
        df_exp[j,i] <- 1
      if (grepl("A little less scary", df_exp[j,i]))
        df_exp[j,i] <- 2
      if (grepl("About as scary", df_exp[j,i]))
        df_exp[j,i] <- 3
      if (grepl("A little more scary", df_exp[j,i]))
        df_exp[j,i] <- 4  
      if (grepl("More scary", df_exp[j,i]))
        df_exp[j,i] <- 5 
      if (grepl("Much more scary", df_exp[j,i]))
        df_exp[j,i] <- 6       
    }
  }
}
```

```{r Restructuring Compare Variables as Numeric}
for (i in Compare.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Compare Variables}
rm(Compare.Cols)
```

```{r Scoring Enjoy Variables}
Enjoy.Cols <- grep(("Enjoy"), colnames(df_exp))
for (i in Enjoy.Cols){
  for (j in 1:length(rownames(df_exp))){
    if (is.na(df_exp[j,i]))
      df_exp[j,i] <- NA
    if (!is.na(df_exp[j,i])){
      if (grepl("Dislike a great deal", df_exp[j,i]))
        df_exp[j,i] <- 0
      if (grepl("Dislike a moderate amount", df_exp[j,i]))
        df_exp[j,i] <- 1
      if (grepl("Dislike a little", df_exp[j,i]))
        df_exp[j,i] <- 2
      if (grepl("Neither like nor dislike", df_exp[j,i]))
        df_exp[j,i] <- 3
      if (grepl("Like a little", df_exp[j,i]))
        df_exp[j,i] <- 4  
      if (grepl("Like a moderate amount", df_exp[j,i]))
        df_exp[j,i] <- 5 
      if (grepl("Like a great deal", df_exp[j,i]))
        df_exp[j,i] <- 6       
    }
  }
}
```

```{r Restructuring Enjoy Variables as Numeric}
for (i in Enjoy.Cols){
  df_exp[,i] <- as.numeric(df_exp[,i])
}
```

```{r Removing Enjoy Variables}
rm(Enjoy.Cols, i, j)
``` 

```{r Copying over participant level information}
for (i in unique(df_exp$PID)){
  
  # Sharing Pre-Exposure specific information
  for (j in which(df_exp$PID == i & df_exp$Stage != "Pre-Exposure")){
    df_exp$Startle[j] <- df_exp$Startle[which(df_exp$PID == i & df_exp$Stage == "Pre-Exposure")]
    df_exp$HH.Times[j] <- df_exp$HH.Times[which(df_exp$PID == i & df_exp$Stage == "Pre-Exposure")]
    df_exp$Fear.Enjoy[j] <- df_exp$Fear.Enjoy[which(df_exp$PID == i & df_exp$Stage == "Pre-Exposure")]
    df_exp[j, grep(names(df_exp),pattern = "Motive\\.")] <- df_exp[which(df_exp$PID == i & df_exp$Stage == "Pre-Exposure"),                                     grep(names(df_exp),pattern = "Motive\\.")]
  }  
  
  # Sharing Immediate Post-Exposure specific information
  for (j in which(df_exp$PID == i & df_exp$Stage != "Immediate Post-Exposure")){
    df_exp[j, 17:34] <- df_exp[which(df_exp$PID == i & df_exp$Stage == "Immediate Post-Exposure"), 17:34]
    df_exp$HH.Compare[j] <- df_exp$HH.Compare[which(df_exp$PID == i & df_exp$Stage == "Immediate Post-Exposure")]
    df_exp$Phobias[j] <- df_exp$Phobias[which(df_exp$PID == i & df_exp$Stage == "Immediate Post-Exposure")]
    df_exp$Phobias.Desc[j] <- df_exp$Phobias.Desc[which(df_exp$PID == i & df_exp$Stage == "Immediate Post-Exposure")]
  }
  
  # Sharing Delayed Post-Exposure specific information
  for (j in which(df_exp$PID == i & df_exp$Stage != "One Week Post-Exposure")){
    if (length(which(df_exp$PID == i & df_exp$Stage == "One Week Post-Exposure")) != 0){
      df_exp$Discuss[j] <- df_exp$Discuss[which(df_exp$PID == i & df_exp$Stage == "One Week Post-Exposure")]
      df_exp$Discuss.Times[j] <- df_exp$Discuss.Times[which(df_exp$PID == i & df_exp$Stage == "One Week Post-Exposure")]
      df_exp$Search[j] <- df_exp$Search[which(df_exp$PID == i & df_exp$Stage == "One Week Post-Exposure")]
      df_exp$Search.Times[j] <- df_exp$Search.Times[which(df_exp$PID == i & df_exp$Stage == "One Week Post-Exposure")]
    }
  }
}
``` 

```{r Exporting my hard work}
write.csv(df_exp,
          file = paste0(Export, "df_exp.csv"), 
          na = "N/A")
```

There's a lot of stage specific details that are not captured post-exposure that are relevant for our analysis, so we've going to pivot the dataframe wider. Before we do that, we need to remove any duplicate entries of our primary ID variables, and since there are some cases where a participant completed the same stage twice, due to errors or whatever, this applies. I'm going to first identify and remove and rows that are full of NAs:

```{r Cleaning Experience Data Rows w/ NA Values}
df_exp <- remove_NAs(df = df_exp, 
                     cols_range = 5:ncol(df_exp))
```

Once again, going to remove columns with only NA Values to only keep relevant data:

```{r Cleaning Experience Data Rows w/ NA Values}
df_exp <- remove_NAs(df = df_exp)
```

and now we'll merge it to the regulation dataframe

```{r Merging Demographics}
df_suppl <- merge(df_suppl,
                  df_exp,
                  by = "PID",
                  all.x = T)
``` 

```{r Cleaning Demographics}
rm(df_exp)
``` 

## RAT

Doing the same for the RAT:

```{r Separating dataframes into sets}
df_rat <- df[,c(18:541)]
``` 

```{r Specifying Example Column Names}
Cols.Example <- c("PID", "Stage", 
                  "Example.1_FirstClick", "Example.1_LastClick", "Example.1_PageSubmit", "Example.1_ClickCount", "Example.1_Response",
                  "Example.1_Answer.FirstClick.", "Example.1_Answer.LastClick", "Example.1_Answer.PageSubmit", "Example.1_Answer.ClickCount",
                  "Example.1_ISI.FirstClick.", "Example.1_ISI.LastClick", "Example.1_ISI.PageSubmit", "Example.1_ISI.ClickCount",
                  "Example.2_FirstClick", "Example.2_LastClick", "Example.2_PageSubmit", "Example.2_ClickCount", "Example.2_Response",
                  "Example.2_Answer.FirstClick.", "Example.2_Answer.LastClick", "Example.2_Answer.PageSubmit", "Example.2_Answer.ClickCount",
                  "Example.2_ISI.FirstClick.", "Example.2_ISI.LastClick", "Example.2_ISI.PageSubmit", "Example.2_ISI.ClickCount",
                  "Example.3_FirstClick", "Example.3_LastClick", "Example.3_PageSubmit", "Example.3_ClickCount", "Example.3_Response",
                  "Example.3_Answer.FirstClick.", "Example.3_Answer.LastClick", "Example.3_Answer.PageSubmit", "Example.3_Answer.ClickCount",
                  "Example.3_ISI.FirstClick.", "Example.3_ISI.LastClick", "Example.3_ISI.PageSubmit", "Example.3_ISI.ClickCount",
                  "Example.4_FirstClick", "Example.4_LastClick", "Example.4_PageSubmit", "Example.4_ClickCount", "Example.4_Response",
                  "Example.4_Answer.FirstClick.", "Example.4_Answer.LastClick", "Example.4_Answer.PageSubmit", "Example.4_Answer.ClickCount",
                  "Example.4_ISI.FirstClick.", "Example.4_ISI.LastClick", "Example.4_ISI.PageSubmit", "Example.4_ISI.ClickCount",
                  "Example.5_FirstClick", "Example.5_LastClick", "Example.5_PageSubmit", "Example.5_ClickCount", "Example.5_Response",
                  "Example.5_Answer.FirstClick.", "Example.5_Answer.LastClick", "Example.5_Answer.PageSubmit", "Example.5_Answer.ClickCount",
                  "Example.5_ISI.FirstClick.", "Example.5_ISI.LastClick", "Example.5_ISI.PageSubmit", "Example.5_ISI.ClickCount",
                  "Example.6_FirstClick", "Example.6_LastClick", "Example.6_PageSubmit", "Example.6_ClickCount", "Example.6_Response",
                  "Example.6_Answer.FirstClick.", "Example.6_Answer.LastClick", "Example.6_Answer.PageSubmit", "Example.6_Answer.ClickCount",
                  "Example.6_ISI.FirstClick.", "Example.6_ISI.LastClick", "Example.6_ISI.PageSubmit", "Example.6_ISI.ClickCount",
                  "Example.7_FirstClick", "Example.7_LastClick", "Example.7_PageSubmit", "Example.7_ClickCount", "Example.7_Response",
                  "Example.7_Answer.FirstClick.", "Example.7_Answer.LastClick", "Example.7_Answer.PageSubmit", "Example.7_Answer.ClickCount",
                  "Example.7_ISI.FirstClick.", "Example.7_ISI.LastClick", "Example.7_ISI.PageSubmit", "Example.7_ISI.ClickCount",
                  "Example.8_FirstClick", "Example.8_LastClick", "Example.8_PageSubmit", "Example.8_ClickCount", "Example.8_Response",
                  "Example.8_Answer.FirstClick.", "Example.8_Answer.LastClick", "Example.8_Answer.PageSubmit", "Example.8_Answer.ClickCount",
                  "Example.8_ISI.FirstClick.", "Example.8_ISI.LastClick", "Example.8_ISI.PageSubmit", "Example.8_ISI.ClickCount",
                  "Example.9_FirstClick", "Example.9_LastClick", "Example.9_PageSubmit", "Example.9_ClickCount", "Example.9_Response",
                  "Example.9_Answer.FirstClick.", "Example.9_Answer.LastClick", "Example.9_Answer.PageSubmit", "Example.9_Answer.ClickCount",
                  "Example.9_ISI.FirstClick.", "Example.9_ISI.LastClick", "Example.9_ISI.PageSubmit", "Example.9_ISI.ClickCount")
``` 

```{r Specifying Response Column Names}
ColTypes <- c("_FirstClick", "_LastClick", "_PageSubmit", "_ClickCount", "_Response",
              "_ISI.FirstClick.", "_ISI.LastClick", "_ISI.PageSubmit", "_ISI.ClickCount")

Groups <- c("A", "B", "C")

Qs <- NA
for (i in 1:length(Groups)){
  Qs <- sort(c(Qs, paste0(Groups[i], "0", 1:9), paste0(Groups[i], 10:15)))
}

Cols.Response <- NA
for (i in 1:length(Qs)){
  Cols.Response <- c(Cols.Response, paste0(Qs[i], ColTypes))
}

Cols.Response <- Cols.Response[-1]

rm(ColTypes, Groups)
``` 

```{r Renaming Columns}
RAT.Cols <- c(Cols.Example, Cols.Response)
colnames(df_rat) <- RAT.Cols

rm(Cols.Example)
```

Now we're going to remove superfluous columns. I don't know what ISI Timing or the Practice columns could possibly tell us

```{r Removing ISI Timing}
df_rat <- df_rat[, -c(grep("Example.", colnames(df_rat)),grep("ISI.", colnames(df_rat)))]
``` 

```{r Pivoting Dataframe Based on Condition}
df_rat <- pivot_longer(data = df_rat,
                       cols = grep("\\_", colnames(df_rat)),
                       names_to = c("Question", ".value"),
                       names_sep = "\\_",
                       values_drop_na = TRUE)
``` 

Now we're going to add the correct answers

```{r Creating Answer Vectors}
Answers <- c("boat", "honey", "pin", "blue", "soap", "fast",
             "copy", "saw", "top", "pack", "under", "sweet",
             "suit", "battle", "power", "watch", "bill", "sugar",
             "bank", "space", "bowl", "ball", "gas", "dog","air",
             "check", "post", "steam", "jelly", "broad", "sore",
             "chair", "day", "pot", "blind", "candle", "cart",
             "camp", "station", "mark", "gate", "field", "tow",
             "salad", "lip")

df_rat$Answer <- NA
for (i in 1:length(rownames(df_rat))){
  for (j in 1:length(Qs)){
    if (df_rat$Question[i] == Qs[j])
      df_rat$Answer[i] <- Answers[j]
  }
}

rm(Answers, Qs, Cols.Response)
``` 

```{r Comparing Responses and desired answers}
df_rat$Correct <- NA
df_rat$Response[is.na(df_rat$Response)] <- "NO ANSWER"
for (i in 1:length(rownames(df_rat))){
  if (is.na(df_rat$Response[i]))
    df_rat$Correct[i] <- 0
  if (tolower(df_rat$Response[i]) != tolower(df_rat$Answer[i]))
    df_rat$Correct[i] <- 0
  if (tolower(df_rat$Response[i]) == tolower(df_rat$Answer[i]))
    df_rat$Correct[i] <- 1 
}

rm(i)
``` 

Great now we're going to create another person level dataframe for the RAT responses and how many folks got right.

```{r Creating a New Dataframe}
Rows <- 1:length(sort(rep(unique(df_rat$PID), 3)))
Cols <- c("PID", "Stage", "Correct", "AvgTime")
df_rat_pl  <- data.frame(matrix(NA, 
                                nrow = length(Rows), 
                                ncol = length(Cols), 
                                dimnames = list(Rows, Cols)))

rm(Rows, Cols)
``` 

```{r Filling the New Dataframe}
df_rat_pl$PID <- sort(rep(unique(df_rat$PID), 3))
df_rat_pl$Stage <- rep(unique(df_rat$Stage), length(unique(df_rat_pl$PID)))
for (i in unique(df_rat_pl$Stage)){
  for (j in unique(df_rat_pl$PID)){
    df_rat_pl$Correct[df_rat_pl$Stage == i & df_rat_pl$PID == j] <- sum(as.numeric(df_rat$Correct[df_rat$Stage == i & df_rat$PID == j]))
    df_rat_pl$AvgTime[df_rat_pl$Stage == i & df_rat_pl$PID == j] <- mean(as.numeric(df_rat$PageSubmit[df_rat$Stage == i & df_rat$PID == j]), na.rm =  T)
    df_rat_pl$AvgTime_correct[df_rat_pl$Stage == i & df_rat_pl$PID == j] <- mean(as.numeric(df_rat$PageSubmit[df_rat$Stage == i & df_rat$PID == j & df_rat$Correct == 1]), na.rm =  T)
  }
}

rm(i, j)
``` 

```{r These rows are indicative of missing data}
df_rat_pl <- df_rat_pl[-which(is.na(df_rat_pl$AvgTime)),]
```

We're going to create a difference variable to see the change over time.

```{r Creating New Difference Variables}
df_rat_pl$CogLoad_Pre <- NA
df_rat_pl$CogLoad_Post <- NA
for (i in unique(df_rat_pl$PID)){
  if (length(which(df_rat_pl$PID == i & (df_rat_pl$Stage == "Pre-Exposure" | df_rat_pl$Stage == "Immediate Post-Exposure"))) == 2){
    df_rat_pl$CogLoad_Pre[df_rat_pl$PID == i] <- df_rat_pl$Correct[df_rat_pl$PID == i & df_rat_pl$Stage == "Pre-Exposure"] - df_rat_pl$Correct[df_rat_pl$PID == i & df_rat_pl$Stage == "Immediate Post-Exposure"]
  }
  if (length(which(df_rat_pl$PID == i & (df_rat_pl$Stage == "Immediate Post-Exposure" | df_rat_pl$Stage == "One Week Post-Exposure"))) == 2){
    df_rat_pl$CogLoad_Post[df_rat_pl$PID == i] <- df_rat_pl$Correct[df_rat_pl$PID == i & df_rat_pl$Stage == "One Week Post-Exposure"] - df_rat_pl$Correct[df_rat_pl$PID == i & df_rat_pl$Stage == "Immediate Post-Exposure"]
  }
}
``` 

```{r Cleaning Space}
rm(df_rat, df, RAT.Cols, i, df_rat_aov)
``` 

```{r Merging Demographics}
df_suppl <- merge(df_suppl,
                  df_rat_pl,
                  by = c("PID", "Stage"),
                  all.y = T)
``` 

```{r Cleaning RAT space}
rm(df_rat_pl)
```

## CONDITION

Participants were assigned to different conditions which determined how they interacted with the stimuli inside. Not super important for our purposes, but I want to at least track it.

```{r Importing Conditions}
df_cond <- read.csv(paste0(Import,"GoalAssignments.csv"),
                    header = T)
``` 

```{r Subsetting Conditions}
df_cond <- subset(df_cond, select = c("PID", "Code", "Date_HH", "Time_HH"))
``` 

```{r Scoring Condition}
df_cond$Code[df_cond$Code == 0] <- "Control"
df_cond$Code[df_cond$Code == 1] <- "Crypt_share"
df_cond$Code[df_cond$Code == 2] <- "Crypt_test"
``` 

```{r Creating a Group Variable}
df_cond$Group <- NA
for (i in 1:nrow(unique(df_cond[,3:4]))){
  for (j in 1:nrow(df_cond)){
    if (all(cbind(df_cond[j,3:4]) == unique(df_cond[,3:4])[i,])){
      df_cond$Group[j] <- paste("Group", i)
    }
  }
}
``` 

```{r Renaming Variables}
df_cond <- rename(df_cond,
                  c(Cond = Code))
``` 

```{r Restructuring Variables}
df_cond$Cond <- as.factor(df_cond$Cond)
df_cond$Date_HH <- as.factor(df_cond$Date_HH)
df_cond$Time_HH <- as.factor(df_cond$Time_HH)
df_cond$Group <- as.factor(df_cond$Group)
``` 

```{r Merging Conditions}
df_suppl <- merge(df_suppl,
                  df_cond,
                  by = "PID",
                  all.x = T)
``` 

```{r Cleaning Conditions}
rm(df_cond,i,j)
``` 

## FEAR RATING

Participants collected fear ratings throughout the house

```{r Importing Conditions}
df_fear <- read.csv(paste0(Import,"fearrating.csv"),
                    header = T)
``` 

```{r Merging Conditions}
df_suppl <- merge(df_suppl,
                  df_fear,
                  by = "PID",
                  all.x = T)
``` 

```{r Cleaning Conditions}
rm(df_fear)
``` 

```{r Merging Emotion Dataframes}
df <- merge(df_reg,
                df_suppl,
                by = c("PID", "Stage"),
                all.x = T)
``` 

```{r Cleaning NRC Space}
rm(df_suppl, df_reg)
```

```{r Writing Data}
write.csv(df, paste0(Export, "df.csv"))
```